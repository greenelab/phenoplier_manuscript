## Methods and materials {#sec:methods}

PhenoPLIER is a framework that integrates gene-trait associations and drug-induced transcriptional responses with groups of functionally-related genes (referred to as gene modules or latent variables/LVs).
This is achieved by combining different computational approaches.
PrediXcan family of methods are used to compute gene-trait associations, while MultiPLIER models are applied on large gene expression compendia to infer latent variables.
PhenoPLIER provides a regression model to compute an LV-trait association, a consensus clustering approach applied to the latent space to learn shared and distinct transcriptomic properties between traits, and an interpretable, LV-based drug repurposing framework.
Details of these methods are provided below.


### The PrediXcan family of methods for gene-based associations {#sec:methods:predixcan}

We used Summary-PrediXcan (S-PrediXcan) [@doi:10.1038/s41467-018-03621-1] and Summary-MultiXcan (S-MultiXcan) [@doi:10.1371/journal.pgen.1007889] as gene-based statistical approaches belonging to the PrediXcan family of methods [@doi:10.1038/ng.3367].
These approaches, which we refer to as TWAS (transcription-wide association studies), only require GWAS summary statistics instead of individual-level genotype and phenotype data.
S-PrediXcan computes the univariate association between a trait and a gene's predicted expression in a single tissue, while S-MultiXcan computes the joint association between a gene's predicted expression in all tissues and a trait.

We provide a brief overview of the methods used in this paper.
We refer to $\mathbf{y}$ as a vector of traits for $n$ individuals, which is centered for convenience.
$\mathbf{\tilde{t}}_l$ is the gene's predicted expression for all individuals in tissue $l$, which is determined by the genotype of SNP $a$ ($X_a$) and its weight in the tissue prediction model ($w_{a}^{l}$).
$\mathbf{t}_l$ is the standardized version of $\mathbf{\tilde{t}}_l$ with a mean of zero and a standard deviation of one.
For more information, please refer to the referenced articles.

, and S-PrediXcan models the trait as a linear function of the gene's expression on multiple tissues using the multivariate model.

We used S-PrediXcan to project genetic associations through gene expression patterns and to identify potential therapeutic targets and drug repurposing opportunities.
Specifically, we used the multivariate model to examine the relationship between gene expression patterns and the clustering of complex traits.

$$
\mathbf{y} = \mathbf{t}_l \gamma_l + \bm{\epsilon}_l,
$$ {#eq:predixcan}

-weighted sum of the allelic effects (EWS-AE) method.

The significance of genetic associations is assessed by computing the $z$-score $\hat{z}_{l}$ for a gene's tissue model $l$.
This score is calculated from the estimated effect size or regression coefficient $\hat{\gamma}_l$ and the error terms $\bm{\epsilon}_l$ with variance $\sigma_{\epsilon}^{2}$.
PrediXcan requires individual-level data to fit this model, while S-PrediXcan uses GWAS summary statistics with the expression-weighted sum of the allelic effects (EWS-AE) method to approximate PrediXcan $z$-scores.

$$
\hat{z}_{l} \approx \sum_{a \in model_{l}} w_a^l \frac{\hat{\sigma}_a}{\hat{\sigma}_l} \frac{\hat{\beta}_a}{\mathrm{se}(\hat{\beta}_a)},
$$ {#eq:spredixcan}

In this study, we used two TWAS methods, S-PrediXcan and PrediXcan, to project genetic associations onto gene expression patterns.
We estimated the genotype variances and covariances using the Genotype-Tissue Expression project (GTEx v8) [@doi:10.1126/science.aaz1776] as the reference panel.
Specifically, we used the variance of each SNP ($\hat{\sigma}_a$), the variance of the predicted expression of a gene in tissue $l$ ($\hat{\sigma}_l$), and the estimated effect size of SNP $a$ from the GWAS ($\hat{\beta}_a$).
We used the $z$-scores of S-PrediXcan to determine the direction of effects (e.g.
whether a higher or lower predicted expression of a gene confers more or less disease risk) in our drug repurposing approach (described below).

.
S-MultiXcan was used to identify associations between gene expression patterns and complex traits.

S-MultiXcan is a summary version of MultiXcan, a powerful method for detecting genetic associations with complex traits.
Unlike PrediXcan, it does not provide the direction of effects, but its main output is the $p$-value (obtained with an F-test) of the multiple tissue model.
In this study, S-MultiXcan was used to identify associations between gene expression patterns and complex traits.

$$
\begin{split}
\mathbf{y} & = \sum_{l=1}^{p} \mathbf{t}_l g_l + \mathbf{e} \\
 & = \mathbf{T} \mathbf{g} + \mathbf{e},
\end{split}
$$ {#eq:multixcan}

the $\chi_{p}^{2}$ test.

MultiXcan and S-MultiXcan are used to project genetic associations onto gene expression patterns.
MultiXcan uses the principal components of a matrix with $p$ columns to avoid collinearity issues.
S-MultiXcan estimates the joint regression of effect sizes and their variances using the marginal estimates from S-PrediXcan.
The significance of the association in S-MultiXcan is estimated with the $\chi_{p}^{2}$ test, which assumes that the estimated effect size vector $\mathbf{\hat{g}}$ is uncorrelated with the error terms $\mathbf{e}$ with variance $\sigma_{e}^{2}$.

$$
\begin{split}
\frac{\mathbf{\hat{g}}^{\top} (\mathbf{T}^{\top}\mathbf{T}) \mathbf{\hat{g}}}{\sigma_{e}^{2}} & \approx \bm{\hat{\gamma}}^{\top} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \left(\frac{\mathbf{T}^{\top} \mathbf{T}}{n-1}\right)^{-1} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \bm{\hat{\gamma}} \\
 & = \mathbf{\hat{z}}^{\top} Cor(\mathbf{T})^{-1} \mathbf{\hat{z}},
\end{split}
$$ {#eq:smultixcan}

S-MultiXcan is used to project genetic associations through gene expression patterns.
It computes a vector of $p$ $z$-scores for each tissue available for the gene and uses the top $k$ principal components to estimate the autocorrelation matrix of the tissue.
This results in a $\chi_k^2$ expression, which assumes that the variance of the error terms in the joint regression is approximately equal to the residual variance of the marginal regressions.
In addition, the global genotype covariance matrix is used to estimate the autocorrelation matrix, while tissue-specific genotype covariances are used to approximate marginal $z$-scores.
S-MultiXcan yields highly concordant estimates compared with MultiXcan, although results are not perfectly correlated across genes.
We used S-MultiXcan results for our LV-based regression model and our cluster analyses of traits.


### TWAS resources {#sec:methods:twas}

We used two large TWAS resources from different cohorts for discovery and replication, both from European ancestries.
PhenomeXcan [@doi:10.1126/sciadv.aba2083] was used as our discovery cohort and provided results on 4,091 traits across different categories.
Supplementary File 1 has all the details about the included GWAS, sample size and disease/trait categories.
PrediXcan family of methods (described before) were used to compute gene-based associations from the publicly available GWAS summary statistics, and fastENLOC [@doi:10.1126/sciadv.aba2083; @doi:10.1016/j.ajhg.2020.11.012] was used to compute a posterior probability of colocalization between GWAS loci and *cis*-eQTL.
We referred to the matrix of $z$-scores from S-PrediXcan (Equation (@eq:spredixcan)) across $q$ traits and $m$ genes in tissue $t$ as $\mathbf{M}^{t} \in \mathbb{R}^{q \times m}$.
This matrix was used in our LV-based drug repurposing framework as it provides direction of effects.
The S-MultiXcan results (22,515 gene associations across 4,091 traits) were used in our LV-based regression framework and our cluster analyses of traits.
For the cluster analyses, we converted the $p$-values to $z$-scores using the probit function, $\Phi^{-1}(1 - p/2)$, where higher $z$-scores correspond to stronger associations.

We used the eMERGE cohort to discover associations between genetic variants and traits.
We ran the same TWAS methods on 309 phecodes from different categories.
Further details about the traits can be found in [@doi:10.1101/2021.10.21.21265225].
We then used the results to replicate the associations found with our LV-based regression framework in PhenomeXcan.


### MultiPLIER and Pathway-level information extractor (PLIER) {#sec:methods:multiplier}

MultiPLIER was used to extract patterns of co-expressed genes from the recount2 gene expression dataset.
The approach applied the Pathway-level Information Extractor Method (PLIER) [@doi:10.1038/s41592-019-0456-1], which uses prior knowledge (canonical pathways) and unsupervised learning to reduce technical noise.
Matrix factorization was used to deconvolute the gene expression data into a set of latent variables (LVs).
This resulted in 987 LVs, reducing the dimensionality of the recount2 dataset.

the following objective function:

We used the PLIER algorithm to analyze a gene expression dataset $\mathbf{Y}^{m \times c}$ with $m$ genes and $c$ experimental conditions.
We also used a prior knowledge matrix $\mathbf{C} \in \{0,1\}^{m \times p}$ for $p$ MSigDB pathways [@doi:10.1016/j.cels.2015.12.004], where $\mathbf{C}_{ij} = 1$ if gene $i$ belongs to pathway $j$.
The objective of the PLIER algorithm was to find $\mathbf{U}$, $\mathbf{Z}$, and $\mathbf{B}$ by minimizing the following objective function:

$$
||\mathbf{Y} - \mathbf{Z}\mathbf{B}||^{2}_{F} + \lambda_1 ||\mathbf{Z} - \mathbf{C}\mathbf{U}||^{2}_{F} + \lambda_2 ||\mathbf{B}||^{2}_{F} + \lambda_3 ||\mathbf{U}||_{L^1}
$$ {#eq:met:plier_func}

We used a model, subject to $\mathbf{U}>0, \mathbf{Z}>0$, to project genetic associations through gene expression patterns.
The model had $l$ latent variables, represented by the gene loadings $\mathbf{Z}^{m \times l}$.
$\mathbf{B}^{l \times c}$ was the latent space for $c$ conditions, and $\mathbf{U}^{p \times l}$ specified which of the $p$ prior-information pathways in $\mathbf{C}$ were represented for each latent variable.
Different regularization parameters, $\lambda_i$, were used in the training step.
$\mathbf{Z}$ was a low-dimensional representation of the gene space, which aligned as much as possible to prior knowledge.
It could represent either a known or novel gene module (i.e., a meaningful biological pattern) or noise.

the following equation:

We used a model to project gene-trait and gene-drug associations into a low-dimensional gene module space for our drug repurposing and cluster analyses.
For example, we projected TWAS associations (either from S-PrediXcan or S-MultiXcan) using the following equation: $\mathbf{M}$

$$
\hat{\mathbf{M}} = (\mathbf{Z}^{\top} \mathbf{Z} + \lambda_{2} \mathbf{I})^{-1} \mathbf{Z}^{\top} \mathbf{M},
$$ {#eq:proj}

We used a matrix, $\hat{\mathbf{M}}^{l \times q}$, to represent traits with gene modules instead of individual genes.
We applied the same method to project drug-induced transcriptional profiles from the LINCS L1000 database, allowing us to create a representation of drugs using gene modules.


### Regression model for LV-trait associations {#sec:methods:reg}

to identify gene-trait associations that are statistically significant and can be used to identify therapeutic targets for drug repurposing or clustering of complex traits.

We adapted the gene-set analysis framework from MAGMA [@doi:10.1371/journal.pcbi.1004219] to TWAS.
Using a competitive test, we predicted gene-trait associations from TWAS using gene weights from a latent variable (LV).
We tested whether the top-weighted genes for an LV had a stronger association with the phenotype than other genes with relatively small or zero weights.
Our model identified gene-trait associations that were statistically significant, allowing us to identify therapeutic targets for drug repurposing or clustering of complex traits.

$$
\mathbf{m}=\beta_{0} + \mathbf{s} \beta_{s} + \sum_{i} \mathbf{x}_{i} \beta_{i} + \bm{\epsilon},
$$ {#eq:reg:model}

The model used in this study is represented by the following equation: $\mathbf{m} = \mathbf{s} \beta + \mathbf{x}_{i}\beta + \bm{\epsilon}$.
Here, $\mathbf{m}$ is a vector of S-MultiXcan gene $p$-values for a trait (with a $-log_{10}$ transformation).
$\mathbf{s}$ is a binary indicator vector, with $s_{\ell}=1$ for the top 1% of genes with the largest loadings for the $\ell$th latent variable (LV) from $\mathbf{Z}_{\ell}$ and zero otherwise.
$\mathbf{x}_{i}$ is a gene property used as a covariate, and $\beta$ are effect sizes (with $\beta_{0}$ as the intercept).
The vector of error terms, $\bm{\epsilon}$, is assumed to have a multivariate normal distribution (MVN) with mean 0 and variance $\sigma^{2} \mathbf{R}$, where $\mathbf{R}$ is the matrix of gene correlations.

We tested the null hypothesis that the difference in trait associations between genes that are part of LV $\ell$ and those outside of it is zero.
To do this, we used the MAGMA framework, incorporating two gene properties as covariates: gene size (defined as the number of PCs retained in S-MultiXcan) and gene density (defined as the ratio of the number of PCs to the number of tissues available).

We used a generalized least squares approach to account for correlations in the error terms $\bm{\epsilon}$.
To do this, we approximated the gene-gene correlation matrix $\mathbf{R}$ by computing the correlations between the model sum of squares (SSM) for each pair of genes under the null hypothesis of no association.
This was done by using the MultiXcan model, which projects the predicted expression matrix $\mathbf{T}_{i} \in \mathbb{R}^{n \times p_i}$ of a gene $i$ across $p_i$ tissues into its top $k_i$ PCs, resulting in matrix $\mathbf{P}_{i} \in \mathbb{R}^{n \times k_i}$.
The SSM for each gene is proportial to $\mathbf{y}^{\top} \mathbf{P}_{i} \mathbf{P}_{i}^{\top} \mathbf{y}$, and the covariances between the SSM of genes $i$ and $j$ is given by $2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})$.
The standard deviations of each SSM are given by $\sqrt{2 \times k_{i}} \times (n - 1)$, and the correlation between the SSMs for genes $i$ and $j$ can be written as follows:

$$
\begin{split}
\mathbf{R}_{ij} & = \frac{2 \times \mathrm{Tr}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}} \times (n - 1)^2} \\
& = \frac{2 \times \mathrm{Tr}(Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \times Cor(\mathbf{P}_{j}, \mathbf{P}_{i}))}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}}},
\end{split}
$$ {#eq:reg:r}

:

We standardize the columns of the matrix $\mathbf{P}$ and calculate the trace of the matrix $\mathrm{Tr}$.
The cross-correlation matrix between the principal components (PCs) is given by $Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \in \mathbb{R}^{k_i \times k_j}$.

$$
\begin{split}
Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) & = Cor(\mathbf{T}_{i} \mathbf{V}_{i}^{\top} \mathrm{diag}(\lambda_i)^{-1/2}, \mathbf{T}_{j} \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2}) \\
& = \mathrm{diag}(\lambda_i)^{-1/2} \mathbf{V}_{i} (\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1}) \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2},
\end{split}
$$ {#eq:reg:cor_pp}

We estimated the correlation of predicted expression levels for genes $i$ in tissue $k$ and gene $j$ in tissue $l$ using [@doi:10.1371/journal.pgen.1007889].
To do this, we used the cross-correlation matrix between the predicted expression levels of genes $i$ and $j$, which was represented as $\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1} \in \mathbb{R}^{p_i \times p_j}$.
Additionally, the eigenvectors and eigenvalues of $\mathbf{T}_{i}$ were represented by columns of $\mathbf{V}_{i}$ and scalars $\lambda_i$, respectively.
We kept only the top eigenvectors using a condition number threshold of $\frac{\max(\lambda_i)}{\lambda_i} < 30$.

$$
\begin{split}
\frac{(\mathbf{T}_{i}^{\top} \mathbf{T}_{j})_{kl}}{n-1} & = Cor(\mathbf{t}_k^i, \mathbf{t}_l^j) \\
 & = \frac{ Cov(\mathbf{t}_k, \mathbf{t}_l) } { \sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ Cov(\sum_{a \in \mathrm{model}_k} w_a^k X_a, \sum_{b \in \mathrm{model}_l} w_b^l X_b) }  {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l} w_a^k w_b^l Cov(X_a, X_b)} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l} w_a^k w_b^l \Gamma_{ab}} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} },
\end{split}
$$ {#eq:reg:corr_genes}

We used the genotype covariance matrix $\Gamma$ from the Genotype-Tissue Expression (GTEx) v8 reference panel to estimate the variance of the predicted expression values of gene $i$ in tissue $k$.
$\Gamma$ is calculated as $(\mathbf{X} - \mathbf{\bar{X}})^{\top} (\mathbf{X} - \mathbf{\bar{X}}) / (n-1)$, where $X_a$ is the genotype of SNP $a$, and $w_a^k$ is the weight of SNP $a$ for gene expression prediction in the tissue model $k$ [@doi:10.1038/s41467-018-03621-1].

$$
\begin{split}
\widehat{\mathrm{var}}(\mathbf{t}_k^i) & = (\mathbf{W}^k)^\top \Gamma^k \mathbf{W}^k \\
 & = \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_k} w_a^k w_b^k \Gamma_{ab}^k.
\end{split}
$$ {#eq:reg:var_gene}

<!--
ERROR: the paragraph below could not be revised with the AI model due to the following error:

The server is overloaded or not ready yet.
-->
Note that, since we used the MultiXcan regression model (Equation (@eq:multixcan)), $\mathbf{R}$ is only an approximation of gene correlations in S-MultiXcan.
As explained before, S-MultiXcan approximates the joint regression parameters in MultiXcan using the marginal regression estimates from S-PrediXcan in (@eq:spredixcan) with some simplifying assumptions and different genotype covariance matrices.
This complicates the derivation of an S-MultiXcan-specific solution to compute $\mathbf{R}$.
To account for this, we used a submatrix $\mathbf{R}_{\ell}$ corresponding to genes that are part of LV $\ell$ only (top 1% of genes) instead of the entire matrix $\mathbf{R}$.
This simplification is conservative since correlations are accounted for top genes only.
Our simulations ([Supplementary Note 1](#sm:reg:null_sim)) show that the model is approximately well-calibrated and can correct for LVs with adjacent and highly correlated genes at the top (e.g., Figure @fig:reg:nulls:qqplot:lv234).
The model can also detect LVs associated with relevant traits (Figure @fig:lv246 and Table @tbl:sup:phenomexcan_assocs:lv246) that are replicated in a different cohort (Table @tbl:sup:emerge_assocs:lv246).

In the case of eMERGE, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.

We computed different correlation matrices for PhenomeXcan and eMERGE.
For PhenomeXcan, we used a single correlation matrix for the UK Biobank GWAS (4,049) which used the same pipeline and included the same set of SNPs.
For the remaining GWAS, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.
In the case of eMERGE, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.
This is necessary to obtain more accurate correlation estimates [@doi:10.1371/journal.pgen.1007889], as we only considered tissue models present in S-PrediXcan results, as well as SNPs present in GWAS used as input for the TWAS approaches (Equation (@eq:reg:corr_genes)).

We ran our regression model for all 987 latent variables (LVs) across the 4,091 traits in PhenomeXcan.
For replication, we ran the same model in the 309 phecodes in eMERGE.
We then adjusted the $p$-values using the Benjamini-Hochberg procedure.


### LV-based drug repurposing approach {#sec:methods:drug}

We compared our LV-based method with a previously published, single-gene approach.
This approach computes a drug-disease score by multiplying each S-PrediXcan set of signed $z$-scores in tissue $t$, $\mathbf{M}^t$, with another set of signed $z$-scores from transcriptional responses profiled in LINCS L1000 [@doi:10.1016/j.cell.2017.10.049], $\mathbf{L}^{c \times m}$ (for $c$ compounds).
The result of this product is $\mathbf{D}^{t,k}=-1 \cdot \mathbf{M}^{t,k} \mathbf{L}^\top$, where $k$ refers to the number of most significant gene associations in $\mathbf{M}^t$ for each trait.
We tested $k$ values of all genes, 50, 100, 250, and 500, and averaged the score ranks across all of these.
We then took the maximum prediction score across all tissues for each drug-disease pair, and the result was $\mathbf{D}_{ij} = \max \{ \mathbf{D}_{ij}^t \mid \forall t \}$.


For the LV-based approach, we projected $\mathbf{M}^{t}$ and $\mathbf{L}$ into the gene module latent space using Equation (@eq:proj).
This resulted in $\hat{\mathbf{M}}^t$ and $\hat{\mathbf{L}}^{l \times c}$.
We then computed $\mathbf{D}^{t,k}=-1 \cdot \hat{\mathbf{L}}^{\top} \hat{\mathbf{M}}^{t,k}$, where $k$ could be all LVs or the top 5, 10, 25 and 50 (since there were an order of magnitude less LVs than genes).


We then used the gene expression data to identify gene co-expression clusters that were associated with the DOID-mapped diseases.

To determine the relationship between drugs and diseases, we mapped PhenomeXcan traits to Disease Ontology IDs (DOID) using the Experimental Factor Ontology and the EFO-UKB-mappings repository.
After this, we used gene expression data to identify gene co-expression clusters that were associated with the DOID-mapped diseases.


### Consensus clustering of traits {#sec:methods:clustering}

We performed two preprocessing steps on the S-MultiXcan results before the cluster analysis.
First, we combined results for traits that mapped to the same Experimental Factor Ontology (EFO) [@doi:10.1093/bioinformatics/btq099] term using the Stouffer's method.
This method takes into account the GWAS sample size for each trait, and converts the $p$-values to $z$-scores.
Second, we divided all $z$-scores for each trait by their sum to reduce the effect of highly polygenic traits.
Finally, we projected the data matrix using Equation (@eq:proj), obtaining a matrix $\hat{\mathbf{M}}$ with 3,752 traits and 987 LVs as the input of our clustering pipeline.


$\pi^* \in \mathbb{N}^n$ such that $i_\pi^*=\arg\max_{i\in\mathbb{N}} \sum_{j=1}^r \mathbb{I}_{i_\pi^*=i_\pi_j}$.

The partitioning of $\hat{\mathbf{M}}$ with $n$ traits into $k$ clusters is represented as a label vector $\pi \in \mathbb{N}^n$.
Consensus clustering is a two-step process.
First, an ensemble $\Pi$ of $r$ partitions of the dataset is created: $\Pi=\{\pi_1, \pi_2, \ldots, \pi_r\}$.
Then, a consolidated solution $\pi^* \in \mathbb{N}^

$$
\pi^* = \mathrm{arg}\,\underset{\hat{\pi}}{\max} Q(\{ \lvert \mathcal{L}^i \lvert \phi(\hat{\pi}_{\mathcal{L}^i}, \pi_{i \mathcal{L}^i}) \mid i \in \{1,\ldots,r\} \}),
$$ {#eq:consensus:obj_func}

We used the Adjusted Rand Index (ARI) [@doi:10.1007/BF01908075] to measure the similarity between two partitions, and the median as a measure of central tendency.
To obtain the consensus partition $\pi^*$, we defined a consensus function $\Gamma\colon \mathbb{N}^{n \times r} \to \mathbb{N}^n$, with $\Pi$ as the input.
This consensus function was based on the Evidence Accumulation Clustering (EAC) paradigm [@doi:10.1109/TPAMI.2005.113].
Here, $\Pi$ was first transformed into a distance matrix $\mathbf{D}_{ij} = d_{ij} / r$, where $d_{ij}$ is the number of times traits $i$ and $j$ were grouped in different clusters across all $r$ partitions in $\Pi$.
Then, a similarity-based clustering algorithm was applied on $\mathbf{D}$ to derive the final partition $\pi^*$.


We generated an ensemble of 4,428 partitions of 3,752 traits by using different algorithms and data representations.
We used three data representations: the raw dataset, its projection into the top 50 principal components, and the embedding learned by UMAP using 50 components.
We applied five clustering algorithms: $k$-means, spectral clustering, a Gaussian mixture model, hierarchical clustering, and DBSCAN.
For $k$-means, spectral clustering and GMM, we specified a range of $k$ between 2 and $\sqrt{n} \approx 60$, and for each $k$ we generated five partitions using random seeds.
For hierarchical clustering, for each $k$, we generated four partitions using common linkage criteria.
For DBSCAN, we combined different ranges for parameters $\epsilon$ and *minPts* based on the procedure in [@doi:10.1088/1755-1315/31/1/012012].
We resampled partitions generated by DBSCAN to ensure an equal representation of this algorithm in the ensemble.


We used spectral clustering on $\mathbf{D}$ to derive the final consensus partitions.
To do this, we transformed $\mathbf{D}$ into a similarity matrix by applying an RBF kernel $\mathrm{exp}(-\gamma \mathbf{D}^2)$ with four different values of $\gamma$ that we empirically determined to be the best.
For each $k$ between 2 and 60, we derived four consensus partitions and selected the one that maximized Equation (@eq:consensus:obj_func).
We further filtered this set of 59 solutions to keep only those with an ensemble agreement larger than the 75th percentile (Supplementary Figure @fig:sup:clustering:agreement), leaving a total of 15 final consensus partitions shown in Figure @fig:clustering:tree.

Our clustering pipeline involves several linear and nonlinear transformations, including PCA, UMAP, and the ensemble transformation using the EAC paradigm (distance matrix $\mathbf{D}$).
To interpret the results, a supervised learning approach was used to detect which gene modules/LVs were the most important for each cluster of traits (Figure {@fig:clustering:design}b).
A decision tree model was trained using the highest resolution partition ($k$=29), with each cluster's traits as the positive class and the rest of the traits as the negative class.
The threshold of the root node was required to be positive and greater than one standard deviation.
The top 20 LVs that best discriminated traits in a cluster from the rest were extracted by repeating this procedure 20 times and removing the selected LV from $\hat{\mathbf{M}}$.

We tested the null hypothesis of no structure in the data by performing several analyses in Supplementary Note 2.
This was done to verify that the clustering results detected by our pipeline were real.


### CRISPR-Cas9 screening {#sec:methods:crispr}

Cell culture was conducted using HepG2 cells obtained from the American Type Culture Collection (ATCC® HB-8065™).
These cells were kept in Eagle's Minimum Essential Medium with L-Glutamine (EMEM) supplemented with 10% Fetal Bovine Serum (FBS) and 1% Pen/Strep (Gibco).
The cells were stored in a humidity-controlled incubator at 37°C with 5% CO2 and maintained at a density not exceeding 80% confluency.

<!--
ERROR: the paragraph below could not be revised with the AI model due to the following error:

The AI model returned an empty string ('')
-->
**Genome-wide lentiviral pooled CRISPR-Cas9 library.** 3rd lentiviral generation, Broad GPP genome-wide Human Brunello CRISPR knockout Pooled library was provided by David Root and John Doench from Addgene (Cat.
73179-LV), and was used for HepG2 cell transduction.
It consists of 76,441 sgRNAs, and targets 19,114 genes in the human genome with an average of 4 sgRNAs per gene.
Each 20nt sgRNA cassette was inserted into the lentiCRIS-PRv2 backbone between U6 promoter and gRNA scaffold.
Through cell transduction, the lentiviral vectors which encode Cas9 were used to deliver the sgRNA cassette containing plasmids into cells during cell replication.
Unsuccessful transduced cells were excluded through puromycin selection.

No-spin lentiviral transduction was used for the screen.
Cells were seeded in 6-well plates coated with Collagen-I, in the presence of 8ug/ml polybrene.
Different volumes of virus (e.g., 0, 50, 100, 200, 250, and 400ul) were assigned to each well, with the final volume of 1.24ml.
16-18 hours post-transduction, the virus/polybrene-containing media was removed and cells were washed twice with 1x DPBS.
24 hours later, cells were trypsinized, diluted (e.g.,1:10) and seeded in pairs of wells of 6-well plates.
60 hours post-transduction, cell media in each well was replaced with fresh EMEM, and 2ug/ml of puromycin was added to one well out of the pair.
2-5 days after puromycin selection, cells in both wells with/without puromycin were collected and counted for viability.
Percentage of Infection (PI%) was calculated by comparing the cell numbers with/without puromycin selection within each pair.
A virus volume of 120ul, yielding 30-40% of transduction efficiency, was chosen for further large-scale viral transduction, as this corresponds to an MOI (Multiplicity of Infection) of ~0.35-0.70.
At this MOI, around 95% of infected cells are predicted to have only one copy of the virus.

To ensure that at least 500 cells per sgRNA were represented, ~200M cells were seeded onto 14 6-well plates.
The cells were transduced with a virus/PB mix medium, and 18hrs later, the virus/PB mix was removed.
The cells were then pooled into T175 flasks, and 2ug/ml of puromycin was added.
The mediums were changed every two days with fresh EMEM and 2ug/ml puromycin.
After 7 days, the cells were collected, pooled, counted, and replated.

Cells were assigned to two groups 9 days after puromycin selection.
Approximately 200 million cells were kept in 100mm dishes and stained with LipidSpotTM 488 (Biotium, Cat.
70065-T) fluorescent dye.
The dye was diluted to 1:100 with DPBS, and 4ml of the staining solution was used for each dish.
The cells were incubated at 37°C for 30 minutes, and images were captured through a fluorescent microscope (EVOS) for GFP signal detection (Figure @fig:sup:crispr:fig1).
An additional 20-30 million cells were collected as Unsorted Control and stored at -80°C for further genomic DNA isolation.

Cells were collected into 50ml tubes, spun at 500 x g for 5 minutes at 4°C, and washed with DPBS.
The cell pellets were then resuspended with a FACS sorting buffer (1x DPBS without Ca2+/Mg2+, 2.5mM EDTA, 25mM HEPES, 1% BSA) which was filter-sterilized and kept at 4°C.
The cell solution was then filtered through a cell strainer and kept on ice, protected from light.
Using a 100μm nozzle, ~20% of GFP-High and GFP-Low cells were collected into 15ml tubes and immediately spun down.
The pellets were stored at -80°C for further genomic DNA isolation.

Genomic DNA (Un-Sorted Control, lentiV2 GFP-High, and lentiV2 GFP-Low) was extracted using the QIAamp DNA Blood Mini Kit (Qiagen, Cat.51104).
The quality and quantity of the gDNA was assessed with UV Spectroscopy (Nanodrop).
A total of 80-160ug of gDNA was isolated for each condition.
The sgRNA cassette and lentiviral specific transgene in the isolated gDNA were verified through PCR (Figure @fig:sup:crispr:fig3).

Generation and sequencing of Illumina libraries was conducted following the protocol of [@pmid:26780180] and the Broad Institute (Figure @fig:sup:crispr:table1).
Each 100ul PCR reaction contained 5ug of gDNA, 5ul of each 10uM P5 and P7 primers, which had been synthesized by Integrated DNA Technologies (IDT) and PAGE purified.
The PCR thermal cycler parameters were set as follows: initial at 95oC for 1min, followed by 24 cycles of denaturation at 94oC for 30 seconds, annealing at 52.5oC for 30 seconds, and extension at 72oC for 30 seconds, with a final elongation at 72oC for 10 minutes.
The expected PCR products were 285bp-293bp in size (Figure @fig:sup:crispr:fig4 A).
The PCR products within the same condition were pooled and purified using SPRIselect beads (Beckman Coulter, Cat.
B23318).
Quantitation of the purified Illumina libraries was done using Qubit, and their quality was analyzed on Bio-analyzer using a High Sensitivity DNA Chip (Figure @fig:sup:crispr:fig4 B).
Finally, the Illumina library samples were pooled and sequenced on Nova-seq 6000, along with a 20% PhiX control v3 library spike-in.


### Code and data availability

We used functional genomics data to construct gene co-expression networks, which were then used to project genetic associations onto the networks.
Clustering of complex traits was done using the Phenoplier algorithm.
We then used the networks to identify therapeutic targets and drug repurposing opportunities. 

The code and data to reproduce all the analyses in this work are available at [https://github.
