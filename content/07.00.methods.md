## Methods and materials {#sec:methods}

PhenoPLIER is a framework that combines different computational approaches to integrate gene-trait associations and drug-induced transcriptional responses with groups of functionally-related genes (referred to as gene modules or latent variables/LVs).
PrediXcan family of methods are used to compute gene-trait associations, while MultiPLIER models are applied on large gene expression compendia to infer latent variables.
PhenoPLIER provides three main features: 1) a regression model to calculate an LV-trait association, 2) a consensus clustering approach applied to the latent space to identify shared and distinct transcriptomic properties between traits, and 3) an interpretable, LV-based drug repurposing framework.
We present the details of these methods below.


### The PrediXcan family of methods for gene-based associations {#sec:methods:predixcan}

We used two methods from the PrediXcan family of gene-based statistical approaches, namely Summary-PrediXcan (S-PrediXcan) and Summary-MultiXcan (S-MultiXcan).
These methods, which we refer to as TWAS (transcription-wide association studies), require only GWAS summary statistics instead of individual-level genotype and phenotype data.
S-PrediXcan computes the univariate association between a trait and a gene's predicted expression in a single tissue, while S-MultiXcan computes the joint association between a gene's predicted expression in all tissues and a trait.
[@doi:10.1038/s41467-018-03621-1; @doi:10.1371/journal.pgen.1007889; @doi:10.1038/ng.3367]

We describe the TWAS methods used in this study.
$\mathbf{y}$ is a vector of traits for $n$ individuals, centered for convenience so that no intercept is necessary.
For each tissue $l$, $\mathbf{\tilde{t}}_l$ is the gene's predicted expression for all individuals, with $X_a$ as the genotype of SNP $a$ and $w_{a}$ its weight in the tissue prediction model $l$.
$\mathbf{t}_l$ is the standardized version of $\mathbf{\tilde{t}}_l$, with mean equal to zero and standard deviation equal to one.
For more information, please refer to the referenced articles.

.
MultiPLIER [@doi:10.1073/pnas.1414190112] is an extension of PrediXcan that uses a multivariate model to account for the interaction between multiple tissues.
PhenomeXcan [@doi:10.1038/s41467-017-01073-3] is an extension of MultiPLIER that uses a multivariate model to predict the trait from gene expression in multiple tissues.
TWAS [@doi:10.1038/ng.3617] is an

$$
\mathbf{y} = \mathbf{t}_l \gamma_l + \bm{\epsilon}_l,
$$ {#eq:predixcan}

<!--  -->
PrediXcan needs individual-level data to fit this model, whereas S-PrediXcan approximates PrediXcan $z$-scores using only GWAS summary statistics with the expression
We estimate the effect size and assess the significance of the association by computing the $z$-score.
The $z$-score, $\hat{z}_{l}$, for a gene's tissue model $l$ is calculated by dividing the estimated effect size, $\hat{\gamma}_l$, by the standard error of $\hat{\gamma}_l$ (se($\hat{\gamma}_l$)).
The error terms, $\bm{\epsilon}_l$, have a variance of $\sigma_{\epsilon}^{2}$.

$$
\hat{z}_{l} \approx \sum_{a \in model_{l}} w_a^l \frac{\hat{\sigma}_a}{\hat{\sigma}_l} \frac{\hat{\beta}_a}{\mathrm{se}(\hat{\beta}_a)},
$$ {#eq:spredixcan}

<!--  -->
Since S-PrediXcan provides tissue-specific direction of effects (for instance, whether a higher or lower predicted expression of a gene confers more or less disease risk), we used the $z$-scores in our drug repurposing approach (described below).
In the TWAS methods, the genotype variances and covariances are estimated using the Genotype-Tissue Expression project (GTEx v8) [@doi:10.1126/science.aaz1776] as the reference panel.
The estimated effect size of a SNP (denoted as $\hat{\beta}_a$) and the variances of the SNP (denoted as $\hat{\sigma}_a$) and predicted expression of a gene in a tissue (denoted as $\hat{\sigma}_l$) are also used.

, which is the association between gene expression and the trait.
To improve the statistical power of the association, we used S-MultiXcan, a summary-based method that combines the results of the individual tissues.

We used S-MultiXcan, a summary-based method, to improve the statistical power of the gene-trait associations.
S-MultiXcan is the summary version of MultiXcan, which is more powerful than PrediXcan in detecting gene-trait associations, although it does not provide the direction of effects.
The main output of MultiXcan is the $p$-value (obtained with an F-test) of the multiple tissue model, which is the association between gene expression and the trait.
S-MultiXcan combines the results of

$$
\begin{split}
\mathbf{y} & = \sum_{l=1}^{p} \mathbf{t}_l g_l + \mathbf{e} \\
 & = \mathbf{T} \mathbf{g} + \mathbf{e},
\end{split}
$$ {#eq:multixcan}

<!--  -->
S-MultiXcan derives the joint regression estimates (effect sizes and their variances) in Equation (@eq:multixcan) using the marginal estimates from S-PrediXcan in Equation (@eq:spredixcan).
Under the null hypothesis of no association, $\mathbf{\hat{g}}^{\top} \frac{\mathbf{T}^{\top}\mathbf{T}}{\sigma_{e}^{2}} \mathbf{\hat{g}} \sim \chi_{p}^{2}$, and therefore the significance of the association in S-MultiXcan is estimated with
MultiPLIER is used to predict gene expression in tissues of interest from the genetic variants, where $\mathbf{T}$ is a matrix with $p$ columns $\mathbf{t}_l$.
$\hat{g}_l$ is the estimated effect size for the predicted gene expression in tissue $l$, and $\mathbf{\hat{g}}$ is a vector with $p$ estimated effect sizes $\hat{g}_l$.
Error terms have variance $\sigma_{e}^{2}$.
To avoid collinearity issues, MultiXcan uses the principal components (PCs) of $\mathbf{T}$ due to the high correlation between predicted expression values for a gene across different tissues.

$$
\begin{split}
\frac{\mathbf{\hat{g}}^{\top} (\mathbf{T}^{\top}\mathbf{T}) \mathbf{\hat{g}}}{\sigma_{e}^{2}} & \approx \bm{\hat{\gamma}}^{\top} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \left(\frac{\mathbf{T}^{\top} \mathbf{T}}{n-1}\right)^{-1} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \bm{\hat{\gamma}} \\
 & = \mathbf{\hat{z}}^{\top} Cor(\mathbf{T})^{-1} \mathbf{\hat{z}},
\end{split}
$$ {#eq:smultixcan}

<!--  -->
To arrive at this expression, S-MultiXcan uses the conservative approximation $\sigma_{e}^{2} \approx \sigma_{\epsilon}^{2}$, that is, the variance of the error terms in the joint regression is approximately equal to the residual variance of the marginal regressions.
Another important point is that $Cor(\mathbf{T})$ is estimated using a global genotype covariance matrix, whereas marginal $\hat{z}_l$ in Equation (@eq:spredixcan) are approximated using tissue-specific genotype covariances.
Although S-MultiXcan yields highly concordant estimates compared with MultiXcan, results are not perfectly correlated across genes [@doi:10.1371/journal.pgen.1007889].
As we explain later, these differences are important for our LV-based regression model when computing the gene-gene correlation matrix.
We used S-MultiXcan results for our LV-based regression model and our cluster analyses of traits.
We used S-MultiXcan to calculate $z$-scores for each gene.
This method utilizes the gene expression values for each tissue to compute a vector of $z$-scores for each gene.
The vector is denoted as $\mathbf{\hat{z}}$, which contains $p$ $z$-scores for the available tissues for the gene.
The autocorrelation matrix of the tissue expression values, $Cor(\mathbf{T})$, is also computed.
Since the matrix $\mathbf{T}^{\top}\mathbf{T}$ is singular for many genes, S-MultiXcan uses the $k$ top principal components to calculate the pseudo-inverse $Cor(\mathbf{T})^{+}$.
As a result, $\mathbf{\hat{z}}^{\top} Cor(\mathbf{T})^{+} \mathbf{\hat{z}} \sim \chi_k^2$.


### TWAS resources {#sec:methods:twas}

<!--  -->
PhenomeXcan [@doi:10.1126/sciadv.aba2083], our discovery cohort, provides results on 4,091 traits across different categories.
Supplemenetary File 1 has all the details about the included GWAS, sample size and disease/trait categories.
<!--  -->
In PhenomeXcan, these publicly available GWAS summary statistics were used to compute
1) gene-based associations with the PrediXcan family of methods (described before), and
2) a posterior probability of colocalization between GWAS loci and *cis*-eQTL with fastENLOC [@doi:10.1126/sciadv.aba2083; @doi:10.1016/j.ajhg.2020.11.012].
<!--  -->
We refer to the matrix of $z$-scores from S-PrediXcan (Equation (@eq:spredixcan)) across $q$ traits and $m$ genes in tissue $t$ as $\mathbf{M}^{t} \in \mathbb{R}^{q \times m}$.
As explained later, matrices $\mathbf{M}^{t}$ were used in our LV-based drug repurposing framework since they provide direction of effects.
<!--  -->
The S-MultiXcan results (22,515 gene associations across 4,091 traits) were used in our LV-based regression framework and our cluster analyses of traits.
For the cluster analyses, we used the $p$-values converted to $z$-scores: $\mathbf{M}=\Phi^{-1}(1 - p/2)$, where $\Phi^{-1}$ is the probit function.
Higher $z$-scores correspond to stronger associations.
We used two large resources for gene co-expression from European ancestries for discovery and replication.
These resources were obtained through the use of a technique called Trans-ethnic Weighted Association Study (TWAS).

We used data from the eMERGE cohort to replicate associations found with our LV-based regression framework in PhenomeXcan.
Specifically, the same TWAS methods were run on 309 phecodes across different categories.
Further information about the traits can be found in [@doi:10.1101/2021.10.21.21265225].


### MultiPLIER and Pathway-level information extractor (PLIER) {#sec:methods:multiplier}

We used MultiPLIER to extract patterns of co-expressed genes from the recount2 dataset.
The MultiPLIER approach applies the pathway-level information extractor method (PLIER) to reduce technical noise.
PLIER uses a matrix factorization approach to deconvolute gene expression data into latent variables (LVs).
The MultiPLIER models reduced the dimensionality of the recount2 dataset to 987 LVs.

the following objective function:

We used MultiPLIER [@doi:10.1093/bioinformatics/btz832] to analyze a gene expression dataset $\mathbf{Y}^{m \times c}$, which contains $m$ genes and $c$ experimental conditions.
We also used a prior knowledge matrix $\mathbf{C} \in \{0,1\}^{m \times p}$ for $p$ MSigDB pathways [@doi:10.1016/j.cels.2015.12.004].
$\mathbf{C}_{ij} = 1$ if gene $i$ belongs to pathway $j$.
MultiPLIER minimized the following objective function to find $\mathbf{U}$, $\mathbf{Z}$, and $\mathbf{B}$:

$$
||\mathbf{Y} - \mathbf{Z}\mathbf{B}||^{2}_{F} + \lambda_1 ||\mathbf{Z} - \mathbf{C}\mathbf{U}||^{2}_{F} + \lambda_2 ||\mathbf{B}||^{2}_{F} + \lambda_3 ||\mathbf{U}||_{L^1}
$$ {#eq:met:plier_func}

<!--  -->
$\mathbf{Z}$ is a low-dimensional representation of the gene space where each LV aligns as much as possible to prior knowledge, and it might represent either a known or novel gene module (i.e., a meaningful biological pattern) or noise.
Subject to $\mathbf{U}>0$ and $\mathbf{Z}>0$, the gene loadings $\mathbf{Z}$ are a matrix of $m$ rows and $l$ columns, and $\mathbf{B}$ is a matrix of $l$ rows and $c$ columns representing the latent space for $c$ conditions.
$\mathbf{U}$ is a matrix of $p$ rows and $l$ columns which specifies which of the $p$ prior-information pathways in $\mathbf{C}$ are represented for each latent variable.
Finally, $\lambda_i$ are different regularization parameters used in the training step.

<!--  -->
For instance, TWAS associations $\mathbf{M}$ (either from S-PrediXcan or S-MultiXcan) were projected using
We used a model to project gene-trait and gene-drug associations into a low-dimensional gene module space.
This model was used for our drug repurposing and cluster analyses, with the gene-trait associations coming from the TWAS, and the gene-drug associations coming from the LINCS L1000.

$$
\hat{\mathbf{M}} = (\mathbf{Z}^{\top} \mathbf{Z} + \lambda_{2} \mathbf{I})^{-1} \mathbf{Z}^{\top} \mathbf{M},
$$ {#eq:proj}

<!--  -->
As explained later, we used the same approach to project drug-induced transcriptional profiles in LINCS L1000 to obtain a representation of drugs using gene modules.
We used a matrix ($\hat{\mathbf{M}}^{l \times q}$) to represent traits with gene modules instead of individual genes.


### Regression model for LV-trait associations {#sec:methods:reg}

using MultiPLIER [@doi:10.1093/bioinformatics/btx715] and PhenomeXcan [@doi:10.1093/bioinformatics/btw711] to generate gene weights for the LV.

We adapted the gene-set analysis framework from MAGMA to TWAS.
To predict gene-trait associations from TWAS, we used a competitive test and gene weights from an LV to test whether the top-weighted genes are more strongly associated with the phenotype than other genes with small or zero weights.
We fit the model using MultiPLIER and PhenomeXcan to generate the gene weights for the LV.

$$
\mathbf{m}=\beta_{0} + \mathbf{s} \beta_{s} + \sum_{i} \mathbf{x}_{i} \beta_{i} + \bm{\epsilon},
$$ {#eq:reg:model}

We use $\mathbf{m}$, a vector of S-MultiXcan gene $p$-values for a trait (with a $-log_{10}$ transformation), $\mathbf{s}$, a binary indicator vector with $s_{\ell}=1$ for the top 1% of genes with the largest loadings for LV $\ell$ (from $\mathbf{Z}_{\ell}$) and zero otherwise, $\mathbf{x}_{i}$, a gene property used as a covariate, and $\beta$ for effect sizes (with $\beta_{0}$ as the intercept).
The vector of error terms, $\bm{\epsilon}$, follows a multivariate normal distribution (MVN) with a mean of zero and a variance-covariance matrix of gene correlations, $\mathbf{R}$.

We tested the null hypothesis that the genetic association of a gene with a trait is zero against the one-sided hypothesis that it is greater than zero.
The difference in trait associations between genes in the latent variable (LV) $\ell$ and genes outside of it was represented by $\beta_{s}$.
We used two gene properties as covariates in the MAGMA framework: gene size (defined as the number of PCs retained in S-MultiXcan) and gene density (defined as the ratio of the number of PCs to the number of tissues available).

We used a generalized least squares approach to account for correlations between the error terms of our linear regression model.
The gene-gene correlation matrix $\mathbf{R}$ was approximated by computing the correlations between the model sum of squares (SSM) for each pair of genes under the null hypothesis of no association.
We derived these correlations from the individual-level MultiXcan model (Equation (@eq:multixcan)), which projects the predicted expression matrix $\mathbf{T}_{i} \in \mathbb{R}^{n \times p_i}$ of a gene $i$ across $p_i$ tissues into its top $k_i$ principal components, resulting in matrix $\mathbf{P}_{i} \in \mathbb{R}^{n \times k_i}$.
The SSM for each gene is proportial to $\mathbf{y}^{\top} \mathbf{P}_{i} \mathbf{P}_{i}^{\top} \mathbf{y}$.
Under the null hypothesis of no association, the covariances between the SSM of genes $i$ and $j$ is given by $2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})$.
The standard deviations of each SSM are given by $\sqrt{2 \times k_{i}} \times (n - 1)$, and the correlation between the SSMs for genes $i$ and $j$ is given by:

$$\rho_{ij} = \frac{2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times (n - 1) \sqrt{2 \times k_{j}} \times (n - 1)}$$

$$
\begin{split}
\mathbf{R}_{ij} & = \frac{2 \times \mathrm{Tr}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}} \times (n - 1)^2} \\
& = \frac{2 \times \mathrm{Tr}(Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \times Cor(\mathbf{P}_{j}, \mathbf{P}_{i}))}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}}},
\end{split}
$$ {#eq:reg:r}

The columns of the matrix $\mathbf{P}$ were standardized and the cross-correlation matrix between the principal components (PCs) was computed.
This matrix, $Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \in \mathbb{R}^{k_i \times k_j}$, was then used to calculate the trace $\mathrm{Tr}$.

$$
\begin{split}
Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) & = Cor(\mathbf{T}_{i} \mathbf{V}_{i}^{\top} \mathrm{diag}(\lambda_i)^{-1/2}, \mathbf{T}_{j} \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2}) \\
& = \mathrm{diag}(\lambda_i)^{-1/2} \mathbf{V}_{i} (\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1}) \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2},
\end{split}
$$ {#eq:reg:cor_pp}

MultiPLIER, which computes the correlation between the two vectors as $\frac{\mathbf{t}_k^i \mathbf{t}_l^j}{\sqrt{\mathbf{t}_k^i \mathbf{t}_k^i \mathbf{t}_l^j \mathbf{t}_l^j}}$.

We used MultiPLIER to estimate the correlation of predicted expression levels for genes $i$ in tissue $k$ and gene $j$ in tissue $l$ $(\mathbf{t}_k^i, \mathbf{t}_l^j)$.
This method computes the correlation between the two vectors as $\frac{\mathbf{t}_k^i \mathbf{t}_l^j}{\sqrt{\mathbf{t}_k^i \mathbf{t}_k^i \mathbf{t}_l^j \mathbf{t}_l^j}}$ [@doi:10.1371/journal.pgen.1007889].
To further refine our analysis, we used S-MultiXcan, which keeps only the top eigenvectors of the cross-correlation matrix $\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1} \in \mathbb{R}^{p_i \times p_j}$ using a condition number threshold of $\frac{\max(\lambda_i)}{\lambda_i} < 30$, where $\lambda_i

$$
\begin{split}
\frac{(\mathbf{T}_{i}^{\top} \mathbf{T}_{j})_{kl}}{n-1} & = Cor(\mathbf{t}_k^i, \mathbf{t}_l^j) \\
 & = \frac{ Cov(\mathbf{t}_k, \mathbf{t}_l) } { \sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ Cov(\sum_{a \in \mathrm{model}_k} w_a^k X_a, \sum_{b \in \mathrm{model}_l} w_b^l X_b) }  {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l} w_a^k w_b^l Cov(X_a, X_b)} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l} w_a^k w_b^l \Gamma_{ab}} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} },
\end{split}
$$ {#eq:reg:corr_genes}

We used MultiPLIER [@doi:10.1093/bioinformatics/btz521] to predict gene expression in each tissue model.
To do so, we used a linear model of the form $\mathbf{y}_i^k = \mathbf{X} \mathbf{w}_i^k + \mathbf{\epsilon}_i^k$, where $\mathbf{y}_i^k$ is the expression level of gene $i$ in tissue $k$, $\mathbf{X}$ is the genotype matrix, $\mathbf{w}_i^k$ is the vector of weights for gene $i$ in tissue $k$, and $\mathbf{\epsilon}_i^k$ is the residual error.
The weights were estimated using the genotype covariance matrix $\Gamma$ derived from the GTEx v8 reference panel.
The variance of the predicted expression values of gene $i$ in tissue $k$ was estimated using the formula described in [@doi:10.1038/s41467-018-03621-1].

$$
\begin{split}
\widehat{\mathrm{var}}(\mathbf{t}_k^i) & = (\mathbf{W}^k)^\top \Gamma^k \mathbf{W}^k \\
 & = \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_k} w_a^k w_b^k \Gamma_{ab}^k.
\end{split}
$$ {#eq:reg:var_gene}

We used the MultiXcan regression model (Equation (@eq:multixcan)) to approximate gene correlations in S-MultiXcan.
To account for the fact that S-MultiXcan approximates the joint regression parameters in MultiXcan using the marginal regression estimates from S-PrediXcan in (@eq:spredixcan) with some simplifying assumptions and different genotype covariance matrices, we used a submatrix $\mathbf{R}_{\ell}$ corresponding to the top 1% of genes that are part of LV $\ell$ instead of the entire matrix $\mathbf{R}$.
Our simulations (Supplementary Note 1) showed that this model is approximately well-calibrated and can correct for LVs with adjacent and highly correlated genes at the top (e.g., Figure @fig:reg:nulls:qqplot:lv234).
It was also able to detect LVs associated with relevant traits (Figure @fig:lv246 and Table @tbl:sup:phenomexcan_assocs:lv246) that were replicated in a different cohort (Table @tbl:sup:emerge_assocs:lv246).

We computed different correlation matrices for the PhenomeXcan and eMERGE approaches.
For PhenomeXcan, most of the GWAS (4,049) were obtained from the UK Biobank using the same pipeline and including the same set of SNPs.
Therefore, we used a single correlation matrix for this set.
For the remaining GWAS, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.
This is necessary to obtain more accurate correlation estimates [@doi:10.1371/journal.pgen.1007889].
In Equation (@eq:reg:corr_genes), for each gene, we only considered tissue models present in S-PrediXcan results, as well as SNPs present in the GWAS used as input for the TWAS approaches.

We ran our regression model for all 987 LVs across 4,091 traits in the PhenomeXcan database.
To replicate the results, we ran the same model in the 309 phecodes of the eMERGE database.
We then adjusted the $p$-values using the Benjamini-Hochberg procedure.


### LV-based drug repurposing approach {#sec:methods:drug}

We used a drug repositioning framework previously used for psychiatry traits [@doi:10.1038/nn.4618] to derive a LV-based method for drug-disease prediction.
This method was compared to a single-gene approach.
For the single-gene method, we computed a drug-disease score by multiplying two sets of signed $z$-scores.
The first set of scores, $\mathbf{M}^t$, was derived from S-PrediXcan and contained information about whether a higher or lower predicted expression of a gene was associated with disease risk.
The second set of scores, $\mathbf{L}^{c \times m}$, was derived from transcriptional responses profiled in LINCS L1000 [@doi:10.1016/j.cell.2017.10.049] and indicated whether a drug increased or decreased the expression of a gene.
The result of the product was $\mathbf{D}^{t,k}=-1 \cdot \mathbf{M}^{t,k} \mathbf{L}^\top$, where $k$ referred to the number of most significant gene associations in $\mathbf{M}^t$ for each trait.
We averaged the score ranks across all $k$ to obtain $\mathbf{D}^t$.
Finally, for each drug-disease pair, we took the maximum prediction score across all tissues: $\mathbf{D}_{ij} = \max \{ \mathbf{D}_{ij}^t \mid \forall t \}$.


<!--  -->
Finally, $\mathbf{D}^{t,k}=-1 \cdot \hat{\mathbf{L}}^{\top} \hat{\mathbf{M}}^{t,k}$, where in this case $k$ could be all LVs or the top 5, 10, 25 and 50 (since we have an order of magnitude less LVs than genes).
We used the same procedure for the LV-based approach.
This involved projecting the matrices $\mathbf{M}^{t}$ and $\mathbf{L}$ into the latent space of gene modules, as specified by Equation (@eq:proj).
This resulted in $\hat{\mathbf{M}}^t$ and $\hat{\mathbf{L}}^{l \times c}$.


We then ran MultiPLIER [@doi:10.1093/bioinformatics/btz638] to identify the top gene co-expression modules associated with each DOID.

We mapped PhenomeXcan traits to Disease Ontology IDs (DOIDs) using the Experimental Factor Ontology (EFO) and a GitHub repository.
To identify the top gene co-expression modules associated with each DOID, we ran MultiPLIER.


### Consensus clustering of traits {#sec:methods:clustering}

We performed two preprocessing steps on the S-MultiXcan results before the cluster analysis.
First, we combined results for traits that mapped to the same Experimental Factor Ontology (EFO) [@doi:10.1093/bioinformatics/btq099] term using the Stouffer's method.
This involved converting $p$-values to $z$-scores and using the equation $\sum w_i M_{ij} / \sqrt{\sum w_i^2}$, where $w_i$ is a weight based on the GWAS sample size for trait $i$, and $M_{ij}$ is the $z$-score for gene $j$.
Second, we divided all $z$-scores for each trait $i$ by their sum to reduce the effect of highly polygenic traits.
We then projected this data matrix using Equation (@eq:proj), obtaining $\hat{\mathbf{M}}$ with $n$=3,752 traits and $l$=987 LVs as the input of our clustering pipeline.


<!--  -->
Consensus clustering approaches consist of two steps:
1) the generation of an ensemble $\Pi$ with $r$ partitions of the dataset: $\Pi=\{\pi_1, \pi_2, \ldots, \pi_r\}$,
and 2) the combination of the ensemble into a consolidated solution defined as:
MultiPLIER was used to find the optimal $k$ clusters, with a minimum of $k=2$ and a maximum of $k=30$, by maximizing the average silhouette width of the partition.

We used MultiPLIER to partition $\hat{\mathbf{M}}$ into $

$$
\pi^* = \mathrm{arg}\,\underset{\hat{\pi}}{\max} Q(\{ \lvert \mathcal{L}^i \lvert \phi(\hat{\pi}_{\mathcal{L}^i}, \pi_{i \mathcal{L}^i}) \mid i \in \{1,\ldots,r\} \}),
$$ {#eq:consensus:obj_func}

<!--  -->
To obtain $\pi^*$, we define a consensus function $\Gamma\colon \mathbb{N}^{n \times r} \to \mathbb{N}^n$ with $\Pi$ as the input.
We used consensus functions based on the evidence accumulation clustering (EAC) paradigm [@doi:10.1109/TPAMI.2005.113], where $\Pi$ is first transformed into a distance matrix
<!--  -->
<!-- $\mathbf{D}_{ij} = \frac{d_{ij}}{r}$, -->
$\mathbf{D}_{ij} = d_{ij} / r$,
<!--  -->
where $d_{ij}$ is the number of times traits $i$ and $j$ were grouped in different clusters across all $r$ partitions in $\Pi$.
Then, $\Gamma$ can be any similarity-based clustering algorithm, which is applied on $\mathbf{D}$ to derive the final partition $\pi^*$.
We used the adjusted Rand index (ARI) [@doi:10.1007/BF01908075] to measure the similarity between two partitions and the median as a measure of central tendency.
$\mathcal{L}^i$ is a set of data indices with known cluster labels for partition $i$.


<!--  -->
For each of these, we applied five clustering algorithms covering a wide range of different assumptions on the data structure: $k$-means [@Arthur2007], spectral clustering [@Ng2001], a Gaussian mixture model (GMM), hierarchical clustering, and DBSCAN [@Ester1996].
<!--  -->
For $k$-means, spectral clustering and GMM, we specified a range of $k$ between 2 and $\sqrt{n} \approx 60$, and for each $k$ we generated five partitions using random seeds.
<!--  -->
For hierarchical clustering, for each $k$, we generated four partitions using common linkage criteria: ward, complete, average and single.
<!--  -->
For DBSCAN, we combined different ranges for parameters $\epsilon$ (the maximum distance between two data points to be considered part of the same neighborhood) and *minPts* (the minimum number of data points in a neighborhood for a data point to be considered a core point), based on the procedure in [@doi:10.1088/1755-1315/31/1/012012].
Specifically, we used *minPts* values from 2 to 125.
For each data representation (raw, PCA and UMAP), we determined a plausible range of $\epsilon$ values by observing the distribution of the mean distance of the *minPts*-nearest neighbors across all data points.
Since some combinations of *minPts* and $\epsilon$ might not produce a meaningful partition (for instance, when all points are detected as noisy or only one cluster is found), we resampled partitions generated by DBSCAN to ensure an equal representation of this algorithm in the ensemble.
<!--  -->
This procedure generated a final ensemble of 4,428 partitions of 3,752 traits.
We used MultiPLIER [@doi:10.1093/bioinformatics/bty945], PhenomeXcan [@doi:10.1093/hmg/ddy096], and TWAS [@doi:10.1038/ng.3712] to generate the ensembles.

We generated ensembles of partitions using three different algorithms (see Figure @fig:clustering:design).
We also used three data representations: the raw dataset, its projection into the top 50 principal components, and a 50-component embedding learned by UMAP [@arxiv:1802.03426].
We employed MultiPLIER [@doi:10.1093/bioinformatics/bty945], PhenomeXcan [@doi:10.1093/hmg/ddy096], and TWAS [@doi:10.1038/ng.3712] to create a highly diverse set of partitions, which is important for obtaining good results [@doi:10.1016/j.ins.2016.04.027; @doi:


<!--  -->
We further filtered this set of 59 solutions to keep only those with an ensemble agreement larger than the 75th percentile (Supplementary Figure @fig:sup:clustering:agreement), leaving a total of 15 final consensus partitions shown in Figure @fig:clustering:tree.
We used spectral clustering to derive the final consensus partitions from $\mathbf{D}$.
We applied an RBF kernel $\mathrm{exp}(-\gamma \mathbf{D}^2)$ to transform $\mathbf{D}$ into a similarity matrix.
To determine the best value for $\gamma$, we empirically tested four different values.
For each $k$ between 2 and 60, we derived four consensus partitions and selected the one that maximized the objective function given by Equation (@eq:consensus:obj_func).

<!-- Clustering interpretation -->
The input data in our clustering pipeline undergoes several linear and nonlinear transformations, including PCA, UMAP and the ensemble transformation using the EAC paradigm (distance matrix $\mathbf{D}$).
Although consensus clustering has clear advantages for biological data [@pmid:27303057], this set of data transformations complicates the interpretation of results.
<!--  -->
To circumvent this, we used a supervised learning approach to detect which gene modules/LVs are the most important for each cluster of traits (Figure {@fig:clustering:design}b).
Note that we did not use this supervised model for prediction but only to learn which features (LVs) were most discriminative for each cluster.
For this, we used the highest resolution partition ($k$=29, although any could be used) to train a decision tree model using each of the clusters as labels and the projected data $\hat{\mathbf{M}}$ as the training samples.
For each $k$, we built a set of binary labels with the current cluster's traits as the positive class and the rest of the traits as the negative class.
Then, we selected the LV in the root node of the trained model only if its threshold was positive and larger than one standard deviation.
Next, we removed this LV from $\hat{\mathbf{M}}$ (regardless of being previously selected or not) and trained the model again.
We repeated this procedure 20 times to extract the top 20 LVs that better discriminate traits in a cluster from the rest.

We performed several analyses under a null hypothesis of no structure in the data to verify that the clustering results detected by our pipeline were real.
This is described in Supplementary Note 2.


### CRISPR-Cas9 screening {#sec:methods:crispr}

HepG2 cells were obtained from ATCC (ATCC® HB-8065™) and maintained in Eagle's Minimum Essential Medium with L-Glutamine (EMEM, Cat.
112-018-101, Quality Biology) supplemented with 10% Fetal Bovine Serum (FBS, Gibco, Cat.16000-044) and 1% Pen/Strep (Gibco, Cat.15140-122).
The cells were kept at 37oC in a humidity-controlled incubator with 5% CO2, and the density was not allowed to exceed 80% confluency.

We used a 3rd generation lentiviral pooled CRISPR-Cas9 library (Cat.
73179-LV) provided by David Root and John Doench from Addgene to transduce HepG2 cells.
This library consists of 76,441 sgRNAs that target 19,114 genes in the human genome, with an average of 4 sgRNAs per gene.
Each sgRNA cassette was inserted between the U6 promoter and gRNA scaffold in the lentiCRIS-PRv2 backbone.
The lentiviral vectors encoding Cas9 were used to deliver the sgRNA cassette containing plasmids into cells during cell replication.
Unsuccessful transduction was excluded through puromycin selection.

The lentiviral titer determination was used for the screen.
Approximate 2.5 million cells were seeded in each well of a Collagen-I coated 6-well plate with 8ug/ml polybrene in EMEM complete media.
A different titrated virus volume (e.g., 0, 50, 100, 200, 250, and 400ul) was assigned to each well.
16-18 hours post-transduction, the virus/polybrene-containing media was removed and the cells were washed twice with 1x DPBS.
Fresh EMEM was added and 24 hours later the cells were trypsinized, diluted (e.g.,1:10) and seeded in pairs of wells of 6-well plates.
60 hours post-transduction, the cell media in each well was replaced with fresh EMEM and 2ug/ml of puromycin was added to one well out of the pair.
2-5 days after puromycin selection, the cells in both wells with/without puromycin were collected and counted for viability.
The percentage of infection (PI%) was obtained by comparing the cell numbers with/without puromycin selection within each pair.
A virus volume of 120ul yielding 30-40% of transduction efficiency was chosen for further large-scale viral transduction, as this corresponds to a multiplicity of infection (MOI) of ~0.35-0.70, at which point around 95% of infected cells are predicted to have only one copy of the virus.

We used lentiviral transduction in HepG2 cells for our screen.
We seeded 2.5M cells in each well of 14 6-well plates and added 8ug/ml of polybrene.
We then added 120ul of virus to each experimental well.
18 hours post-transduction, we removed the virus/PB mix medium and collected, counted, and pooled the cells into T175 flasks.
We then added 2ug/ml of puromycin to each flask and changed the medium every two days with fresh EMEM, topped with 2ug/ml puromycin.
After seven days of puromycin selection, we collected, pooled, counted, and replated the cells.
This process ensured a representation of at least 500 cells per sgRNA and an MOI between 0.3-0.4 to ensure 95% of infected cells get only one viral particle per cell.

Cells were assigned to two groups 9 days after puromycin selection.
20-30M cells were collected as Unsorted Control and the cell pellet was spun down at 500 x g for 5 minutes at 4oC.
The dry pellet was stored at -80oC for further genomic DNA isolation.
The remaining cells (approximately 200M) were kept in 100mm dishes and stained with LipidSpotTM 488 (Biotium, Cat.
70065-T), a fluorescent dye.
The staining solution was diluted to 1:100 with DPBS and 4ml of this solution was added to each dish.
The cells were incubated at 37oC for 30 minutes and images of the GFP signal were captured through a fluorescent microscope EVOS (Figure @fig:sup:crispr:fig1).

Cells were collected into 50 ml tubes and spun at 500 x g for 5 min at 4°C.
The cell pellets were then resuspended with FACS Sorting Buffer (1x DPBS without Ca2+/Mg2+, 2.5 mM EDTA, 25 mM HEPES, 1% BSA; the solution was filter-sterilized and kept at 4°C), pipetted gently to create single cells, and filtered through a cell strainer (Falcon, Cat.
352235).
The cells were sorted on FACSJazz with a 100 µm nozzle, and ~20% of each GFP-High and GFP-Low (Figure @fig:sup:crispr:fig2) were collected into 15 ml tubes.
The cells were then immediately spun down and the pellets were stored at -80°C for further genomic DNA isolation.

Genomic DNA was isolated from three conditions (Un-Sorted Control, lentiV2 GFP-High, and lentiV2 GFP-Low) using the QIAamp DNA Blood Mini Kit (Qiagen, Cat.51104).
The quality and quantity of the gDNA was assessed via UV Spectroscopy (Nanodrop), with a total of 80-160ug of gDNA isolated for each condition.
The presence of the sgRNA cassette and lentiviral specific transgene in the isolated gDNA was confirmed via PCR (Figure @fig:sup:crispr:fig3).

Illumina libraries were generated and sequenced to amplify the fragment containing the sgRNA cassette.
Primers were synthesized from the Integrated DNA Technologies (IDT) following the protocol from the Broad Institute (Figure @fig:sup:crispr:table1).
Each primer contained a 0-8 nucleotide stagger sequence in the P5 and an 8bp uniquely barcoded sequence in the P7.
32 PCR reactions, each containing 5ug of gDNA, 5ul of 10uM P5 and P7, were set up for each condition.
The PCR Thermal Cycler Parameters were Initial at 95oC for 1min; followed by 24 cycles of Denaturation at 94oC for 30 seconds, Annealing at 52.5oC for 30 seconds, and Extension at 72oC for 30 seconds.
A final Elongation at 72oC for 10 minutes was performed.
285bp-293bp PCR products were expected (Figure @fig:sup:crispr:fig4 A).
The PCR products were pooled and purified using SPRIselect beads (Beckman Coulter, Cat.
B23318).
The quality of the library was analyzed on Bio-analyzer using High Sensitivity DNA Chip, with a single approximate 285bp peak expected (Figure @fig:sup:crispr:fig4 B).
The libraries were then sequenced on Nova-seq 6000, with a 20% PhiX control v3 library spike-in.


### Code and data availability

We used MultiPLIER to perform gene co-expression analysis, PhenomeXcan to map genetic associations to gene expression patterns, and TWAS to project genetic associations through gene expression patterns.

The code and data to reproduce all the analyses in this work can be found at [https://github.com/greenelab/phenoplier](https://github.com/greenelab
