## Methods and materials {#sec:methods}

PhenoPLIER is a framework that combines several computational approaches to integrate gene-trait associations and drug-induced transcriptional responses with groups of functionally-related genes (referred to as gene modules or latent variables/LVs).
PrediXcan family of methods are used to calculate gene-trait associations, while MultiPLIER models are applied to large gene expression compendia to infer latent variables.
PhenoPLIER provides three key functions: 1) a regression model to compute an LV-trait association, 2) a consensus clustering approach applied to the latent space to identify shared and distinct transcriptomic properties between traits, and 3) an interpretable, LV-based drug repurposing framework.
We provide more details on these methods below.


### The PrediXcan family of methods for gene-based associations {#sec:methods:predixcan}

We used Summary-PrediXcan (S-PrediXcan) and Summary-MultiXcan (S-MultiXcan) as the gene-based statistical approaches.
These belong to the PrediXcan family of methods, which we broadly refer to as TWAS (transcription-wide association studies).
S-PrediXcan computes the univariate association between a trait and a gene's predicted expression in a single tissue, while S-MultiXcan computes the joint association between a gene's predicted expression in all tissues and a trait.
Both S-PrediXcan and S-MultiXcan only require GWAS summary statistics, instead of individual-level genotype and phenotype data.

We briefly provide the details of TWAS methods necessary to explain our regression framework later (see the referenced articles for more information).
We refer to $\mathbf{y}$ as a vector of traits for $n$ individuals, which has been centered (so that no intercept is necessary).
The gene's predicted expression in tissue $l$, $\mathbf{\tilde{t}}_l = \sum_{a \in \mathrm{model}_l} w_{a}^{l} X_{a}$, is determined by the genotype of SNP $a$, $X_a$, and its weight in the tissue prediction model $l$, $w_{a}$.
The standardized version of $\mathbf{\tilde{t}}_l$ is denoted as $\mathbf{t}_l$ and has a mean equal to zero and standard deviation equal to one.

, while S-PrediXcan models the trait as a linear function of the gene's expression on multiple tissues using the multivariate model.

We used S-PrediXcan to project genetic associations through gene expression patterns, which highlighted disease etiology and drug mechanisms.
This method models the trait as a linear function of gene expression on multiple tissues using a multivariate model.
This enabled us to identify therapeutic targets and drug repurposing opportunities.
We also used clustering of complex traits to further improve the accuracy of our results.

$$
\mathbf{y} = \mathbf{t}_l \gamma_l + \bm{\epsilon}_l,
$$ {#eq:predixcan}

of the gene in the tissue of interest.

We assess the significance of the association between genetic studies and functional genomics by computing the $z$-score $\hat{z}_{l}=\hat{\gamma}_l / \mathrm{se}(\hat{\gamma}_l)$ for a gene's tissue model $l$.
Here, $\hat{\gamma}_l$ is the estimated effect size or regression coefficient, and $\bm{\epsilon}_l$ are the error terms with variance $\sigma_{\epsilon}^{2}$.
PrediXcan requires individual-level data to fit this model, while S-PrediXcan approximates the $z$-scores using GWAS summary statistics and the expression of the gene in the tissue of interest.
This helps to identify gene co-expression patterns, therapeutic targets, and drug repurposing opportunities for clustering of complex traits.

$$
\hat{z}_{l} \approx \sum_{a \in model_{l}} w_a^l \frac{\hat{\sigma}_a}{\hat{\sigma}_l} \frac{\hat{\beta}_a}{\mathrm{se}(\hat{\beta}_a)},
$$ {#eq:spredixcan}

We used two methods for projecting genetic associations to gene expression: S-PrediXcan [@doi:10.1101/gr.244737.116] and TWAS [@doi:10.1038/ng.3583].
Both methods use linear mixed models to estimate the effect size of a single nucleotide polymorphism (SNP) on the predicted expression of a gene in a given tissue.
Specifically, S-PrediXcan estimates the effect size of a SNP on the predicted expression of a gene in all tissues, while TWAS estimates the effect size of a SNP on the predicted expression of a gene in a single tissue.
For both methods, the effect size of a SNP is estimated using the following equation: $\hat{\beta}_a = \frac{\Sigma_{l=1}^L \hat{\sigma}_a \hat{\sigma}_l \hat{\rho}_{al}}{\Sigma_{l=1}^L \hat{\sigma}_l^2}$, 

In this paper, we used two methods for projecting genetic associations to gene expression: S-PrediXcan and TWAS.
S-PrediXcan estimates the effect size of a single nucleotide polymorphism (SNP) on the predicted expression of a gene in all tissues, while TWAS estimates the effect size of a SNP on the predicted expression of a gene in a single tissue.
We used the Genotype-Tissue Expression project (GTEx v8) as a reference panel to

, which is used to assess the association between gene expression and the trait of interest.
S-MultiXcan is a faster version of MultiXcan that is used to detect gene-trait associations by summarizing the results from multiple tissues.

S-MultiXcan is a summary version of MultiXcan, a tool used to detect genetic associations between gene expression and a trait of interest.
MultiXcan is more powerful than PrediXcan in detecting gene-trait associations, although it does not provide the direction of effects.
S-MultiXcan is a faster version of MultiXcan that produces a $p$-value (obtained with an F-test) to assess the association between gene expression and the trait of interest.

$$
\begin{split}
\mathbf{y} & = \sum_{l=1}^{p} \mathbf{t}_l g_l + \mathbf{e} \\
 & = \mathbf{T} \mathbf{g} + \mathbf{e},
\end{split}
$$ {#eq:multixcan}

the $\chi_{p}^{2}$ statistic.

MultiXcan uses principal components of a matrix $\mathbf{T}$ with $p$ columns $\mathbf{t}_l$ to avoid collinearity issues.
This matrix is used to estimate effect sizes $\mathbf{\hat{g}}$ with $p$ elements $\hat{g}_l$ for the predicted gene expression in tissue $l$.
The error terms have variance $\sigma_{e}^{2}$.
S-MultiXcan derives the joint regression estimates (effect sizes and their variances) from the marginal estimates of S-PrediXcan.
The significance of the association in S-MultiXcan is estimated with the $\chi_{p}^{2}$ statistic, which follows the null hypothesis of no association, $\mathbf{\hat{g}}^{\top} \frac{\mathbf{T}^{\top}\mathbf{T}}{\sigma_{e}^{2}} \mathbf{\hat{g}} \sim \chi_{p}^{2}$.

$$
\begin{split}
\frac{\mathbf{\hat{g}}^{\top} (\mathbf{T}^{\top}\mathbf{T}) \mathbf{\hat{g}}}{\sigma_{e}^{2}} & \approx \bm{\hat{\gamma}}^{\top} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \left(\frac{\mathbf{T}^{\top} \mathbf{T}}{n-1}\right)^{-1} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \bm{\hat{\gamma}} \\
 & = \mathbf{\hat{z}}^{\top} Cor(\mathbf{T})^{-1} \mathbf{\hat{z}},
\end{split}
$$ {#eq:smultixcan}

S-MultiXcan was used to project genetic associations through gene expression patterns.
This method computes a vector of $p$ $z$-scores for each tissue available for the gene, denoted as $\mathbf{\hat{z}}$, and an autocorrelation matrix of $\mathbf{T}$, denoted as $Cor(\mathbf{T})$.
Since $\mathbf{T}^{\top}\mathbf{T}$ is singular for many genes, S-MultiXcan computes the pseudo-inverse $Cor(\mathbf{T})^{+}$ using the $k$ top PCs.
This allows S-MultiXcan to arrive at the expression $\mathbf{\hat{z}}^{\top} Cor(\mathbf{T})^{+} \mathbf{\hat{z}} \sim \chi_k^2$.
To do this, S-MultiXcan uses the approximation that the variance of the error terms in the joint regression is approximately equal to the residual variance of the marginal regressions.
Additionally, $Cor(\mathbf{T})$ is estimated using a global genotype covariance matrix, whereas marginal $\hat{z}_l$ in Equation (@eq:spredixcan) are approximated using tissue-specific genotype covariances.
S-MultiXcan yields highly concordant estimates compared with MultiXcan, although results are not perfectly correlated across genes [@doi:10.1371/journal.pgen.1007889].
We used S-MultiXcan results for our LV-based regression model and our cluster analyses of traits.


### TWAS resources {#sec:methods:twas}

We used two large TWAS resources from different cohorts for discovery and replication, both from European ancestries.
The discovery cohort, PhenomeXcan, provided results on 4,091 traits across different categories.
Supplementary File 1 contains details about the included GWAS, sample size, and disease/trait categories.
In PhenomeXcan, publicly available GWAS summary statistics were used to compute gene-based associations with the PrediXcan family of methods (as described previously) and a posterior probability of colocalization between GWAS loci and *cis*-eQTL with fastENLOC.
The resulting matrix of $z$-scores from S-PrediXcan (Equation (@eq:spredixcan)) across $q$ traits and $m$ genes in tissue $t$ was referred to as $\mathbf{M}^{t} \in \mathbb{R}^{q \times m}$.
This matrix was used in our LV-based drug repurposing framework since it provides direction of effects.
The S-MultiXcan results (22,515 gene associations across 4,091 traits) were used in our LV-based regression framework and our cluster analyses of traits.
For the cluster analyses, we converted the $p$-values to $z$-scores using the probit function: $\mathbf{M}=\Phi^{-1}(1 - p/2)$.
Higher $z$-scores correspond to stronger associations.

We used the eMERGE cohort to discover genetic associations, where we applied the TWAS methods to 309 phecodes across different categories.
For more information on the traits, please see [@doi:10.1101/2021.10.21.21265225].
We then used the results from this cohort to replicate the associations found with our LV-based regression framework in PhenomeXcan.


### MultiPLIER and Pathway-level information extractor (PLIER) {#sec:methods:multiplier}

MultiPLIER was used to extract patterns of co-expressed genes from recount2, a large gene expression dataset.
To reduce technical noise, the pathway-level information extractor method (PLIER) was applied [@doi:10.1038/s41592-019-0456-1].
PLIER uses a matrix factorization approach that deconvolutes gene expression data into a set of latent variables (LVs).
Each LV represents a gene module.
After applying MultiPLIER, the dimensionality of recount2 was reduced to 987 LVs.

the following objective function:

Given a gene expression dataset $\mathbf{Y}$ with $m$ genes and $c$ experimental conditions, and a prior knowledge matrix $\mathbf{C}$, which indicates the presence of $p$ pathways from the MSigDB database [@doi:10.1016/j.cels.2015.12.004], PLIER was used to find $\mathbf{U}$, $\mathbf{Z}$, and $\mathbf{B}$ by minimizing the objective function:

$$
||\mathbf{Y} - \mathbf{Z}\mathbf{B}||^{2}_{F} + \lambda_1 ||\mathbf{Z} - \mathbf{C}\mathbf{U}||^{2}_{F} + \lambda_2 ||\mathbf{B}||^{2}_{F} + \lambda_3 ||\mathbf{U}||_{L^1}
$$ {#eq:met:plier_func}

We use $\mathbf{U}$, $\mathbf{Z}$, $\mathbf{B}$, and $\lambda_i$ to project genetic associations through gene expression patterns.
$\mathbf{U}$ is a matrix with positive values, $\mathbf{Z}$ is a matrix of gene loadings with $l$ latent variables, $\mathbf{B}$ is a latent space for $c$ conditions, and $\lambda_i$ are regularization parameters used in the training step.
$\mathbf{Z}$ is a low-dimensional representation of the gene space where each latent variable (LV) aligns with prior knowledge.
This representation may represent either a known or novel gene module (i.e., a meaningful biological pattern) or noise.

the following equation: $\mathbf{M'} = \mathbf{C}^{-1}\mathbf{M}$.

We used a model to project gene-trait and gene-drug associations from two sources into a low-dimensional gene module space.
Specifically, the associations from Transcriptome-Wide Association Studies (TWAS) and the Library of Network-Based Cellular Signatures (LINCS) L1000 were projected using the equation $\mathbf{M'} = \mathbf{C}^{-1}\mathbf{M}$.
This analysis enabled us to conduct drug repurposing and cluster analyses.

$$
\hat{\mathbf{M}} = (\mathbf{Z}^{\top} \mathbf{Z} + \lambda_{2} \mathbf{I})^{-1} \mathbf{Z}^{\top} \mathbf{M},
$$ {#eq:proj}

We used a matrix $\hat{\mathbf{M}}^{l \times q}$ to represent traits with gene modules instead of single genes.
We applied the same approach to project drug-induced transcriptional profiles in LINCS L1000, resulting in a representation of drugs using gene modules.
This will be discussed in more detail later.


### Regression model for LV-trait associations {#sec:methods:reg}

using a two-step approach: (1) a gene-level model to identify a gene-level association with the trait, and (2) a gene-set model to identify a gene-set association with the trait.

We adapted the gene-set analysis framework from MAGMA [@doi:10.1371/journal.pcbi.1004219] to TWAS.
We used a competitive test to predict gene-trait associations from TWAS using gene weights from an LV.
This test aimed to determine whether the genes with the highest weights for an LV were more strongly associated with the phenotype than other genes with relatively small or zero weights.
We followed a two-step approach to fit the model: (1) a gene-level model to identify a gene-level association with the trait, and (2) a gene-set model to identify a gene-set association with the trait.

$$
\mathbf{m}=\beta_{0} + \mathbf{s} \beta_{s} + \sum_{i} \mathbf{x}_{i} \beta_{i} + \bm{\epsilon},
$$ {#eq:reg:model}

The model used in this study is a multi-level linear regression, where the vector of gene expression $p$-values $\mathbf{m}$ for a trait is regressed on the binary indicator vector $\mathbf{s}$ (which is set to 1 for the top 1% of genes with the largest loadings for each latent variable $\ell$) and gene property $\mathbf{x}_{i}$ as covariates, with effect sizes $\beta$ (including the intercept $\beta_{0}$).
The vector of error terms $\bm{\epsilon}$ is assumed to follow a multivariate normal distribution with a variance-covariance matrix $\mathbf{R}$ based on gene correlations.

We tested the null hypothesis $\beta_{s} = 0$ against the one-sided hypothesis $\beta_{s} > 0$ to determine the difference in trait associations between genes that are part of the latent variable $\ell$ and those that are not.
We used the MAGMA framework, incorporating two gene properties as covariates: gene size (the number of PCs retained in S-MultiXcan) and gene density (the ratio of the number of PCs to the number of tissues available).

\begin{equation}\label{eq:corr_ssm}
    \mathrm{Corr}(\mathbf{y}^{\top} \mathbf{P}_{i} \mathbf{P}_{i}^{\top} \mathbf{y}, \mathbf{y}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{y}) = \frac{2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times (n - 1) \sqrt{2 \times k_{j}} \times (n - 1)}.
\end{equation}

We used a generalized least squares approach to account for correlations between error terms in the PrediXcan family of methods.
To do this, we approximated the gene-gene correlation matrix $\mathbf{R}$ by computing the correlations between the model sum of squares (SSM) for each pair of genes under the null hypothesis of no association.
These correlations were calculated using the MultiXcan model, which projects the predicted expression matrix $\mathbf{T}_{i}$ of a gene $i$ across $p_i$ tissues into its top $k_i$ principal components, resulting in matrix $\mathbf{P}_{i}$.
The correlation between the SSMs for genes $i$ and $j$ was then calculated using Equation \ref{eq:corr_ssm}.

$$
\begin{split}
\mathbf{R}_{ij} & = \frac{2 \times \mathrm{Tr}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}} \times (n - 1)^2} \\
& = \frac{2 \times \mathrm{Tr}(Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \times Cor(\mathbf{P}_{j}, \mathbf{P}_{i}))}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}}},
\end{split}
$$ {#eq:reg:r}

This paragraph can be revised as follows:

The cross-correlation matrix between PCs is given by the trace of a matrix, $\mathrm{Tr}$, where the columns, $\mathbf{P}$, are standardized.
This matrix is denoted as $Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \in \mathbb{R}^{k_i \times k_j}$.

$$
\begin{split}
Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) & = Cor(\mathbf{T}_{i} \mathbf{V}_{i}^{\top} \mathrm{diag}(\lambda_i)^{-1/2}, \mathbf{T}_{j} \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2}) \\
& = \mathrm{diag}(\lambda_i)^{-1/2} \mathbf{V}_{i} (\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1}) \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2},
\end{split}
$$ {#eq:reg:cor_pp}

We used [@doi:10.1371/journal.pgen.1007889] to estimate the correlation of predicted expression levels for genes $i$ in tissue $k$ and gene $j$ in tissue $l$.
For this purpose, we calculated the cross-correlation matrix $\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1} \in \mathbb{R}^{p_i \times p_j}$ between the predicted expression levels of genes $i$ and $j$.
We then kept only the top eigenvectors using a condition number threshold of $\frac{\max(\lambda_i)}{\lambda_i} < 30$, where $\mathbf{V}_{i}$ and $\lambda_i$ are the eigenvectors and eigenvalues of $\mathbf{T}_{i}$, respectively.

$$
\begin{split}
\frac{(\mathbf{T}_{i}^{\top} \mathbf{T}_{j})_{kl}}{n-1} & = Cor(\mathbf{t}_k^i, \mathbf{t}_l^j) \\
 & = \frac{ Cov(\mathbf{t}_k, \mathbf{t}_l) } { \sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ Cov(\sum_{a \in \mathrm{model}_k} w_a^k X_a, \sum_{b \in \mathrm{model}_l} w_b^l X_b) }  {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l} w_a^k w_b^l Cov(X_a, X_b)} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l} w_a^k w_b^l \Gamma_{ab}} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} },
\end{split}
$$ {#eq:reg:corr_genes}

We used the genotype covariance matrix $\Gamma$ from GTEx v8 as the reference panel for all TWAS methods described here.
This matrix is calculated by subtracting the mean of genotype $\mathbf{X}$ from itself and then dividing it by $(n-1)$.
For each SNP $a$, we also calculated the weight $w_a^k$ for gene expression prediction in the tissue model $k$.
The variance of the predicted expression values of gene $i$ in tissue $k$ is estimated according to [@doi:10.1038/s41467-018-03621-1].

$$
\begin{split}
\widehat{\mathrm{var}}(\mathbf{t}_k^i) & = (\mathbf{W}^k)^\top \Gamma^k \mathbf{W}^k \\
 & = \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_k} w_a^k w_b^k \Gamma_{ab}^k.
\end{split}
$$ {#eq:reg:var_gene}

We used the MultiXcan regression model (Equation (@eq:multixcan)) to approximate gene correlations in S-MultiXcan.
To account for this approximation, we used a submatrix $\mathbf{R}_{\ell}$ corresponding to genes that are part of LV $\ell$ only (top 1% of genes).
Our simulations ([Supplementary Note 1](#sm:reg:null_sim)) show that the model is approximately well-calibrated and can correct for LVs with adjacent and highly correlated genes at the top (e.g., Figure @fig:reg:nulls:qqplot:lv234).
Additionally, the model was able to detect LVs associated with relevant traits (Figure @fig:lv246 and Table @tbl:sup:phenomexcan_assocs:lv246) that were replicated in a different cohort (Table @tbl:sup:emerge_assocs:lv246).

For eMERGE, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.

We computed correlation matrices for PhenomeXcan and eMERGE by considering only tissue models present in S-PrediXcan results and SNPs present in GWAS used as input for TWAS approaches.
This was necessary to obtain more accurate correlation estimates [@doi:10.1371/journal.pgen.1007889].
For PhenomeXcan, 4,049 GWAS were obtained from the UK Biobank using the same pipeline and including the same set of SNPs, so a single correlation matrix was used.
For the remaining traits, we used a single correlation matrix for each group that shared the same or most of the SNPs.
For eMERGE, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.

We ran our regression model for all 987 latent variables (LVs) across the 4,091 traits in the PhenomeXcan dataset.
To replicate our findings, we repeated the model using the 309 phecodes in the eMERGE dataset.
We adjusted the $p$-values using the Benjamini-Hochberg procedure to account for multiple comparisons.


### LV-based drug repurposing approach {#sec:methods:drug}

We compared our LV-based method to a single-gene approach previously used for psychiatry traits [@doi:10.1038/nn.4618].
This approach computes a drug-disease score by multiplying two sets of signed $z$-scores.
The first set, $\mathbf{M}^t$, contains information about whether a higher or lower predicted expression of a gene is associated with disease risk.
The second set, $\mathbf{L}^{c \times m}$, indicates whether a drug increases or decreases the expression of a gene (for $c$ compounds).
We averaged the score ranks across the number of most significant gene associations in $\mathbf{M}^t$ (either all genes or the top 50, 100, 250, and 500) to obtain $\mathbf{D}^t$.
For each drug-disease pair, we took the maximum prediction score across all tissues: $\mathbf{D}_{ij} = \max \{ \mathbf{D}_{ij}^t \mid \forall t \}$.


For the LV-based approach, we used Equation (@eq:proj) to project $\mathbf{M}^{t}$ and $\mathbf{L}$ into the gene module latent space.
This resulted in $\hat{\mathbf{M}}^t$ and $\hat{\mathbf{L}}^{l \times c}$, respectively.
Following this, we computed $\mathbf{D}^{t,k}=-1 \cdot \hat{\mathbf{L}}^{\top} \hat{\mathbf{M}}^{t,k}$, where $k$ could be all LVs or the top 5, 10, 25 and 50 (as there were an order of magnitude fewer LVs than genes).


We then used a hierarchical clustering approach to group the PhenomeXcan traits into disease-related clusters.

We mapped PhenomeXcan traits to Disease Ontology IDs (DOID) using the gold standard of drug-disease medical indications described by DOID [@doi:10.1093/nar/gky1032].
We then used the Experimental Factor Ontology [@doi:10.1093/bioinformatics/btq099] and a GitHub repository [@url:https://github.com/EBISPOT/EFO-UKB-mappings] to map the PhenomeXcan traits to DOID.
Finally, we used hierarchical clustering to group the PhenomeXcan


### Consensus clustering of traits {#sec:methods:clustering}

We preprocessed the S-MultiXcan results before performing the cluster analysis.
First, we combined $z$-scores for traits that mapped to the same Experimental Factor Ontology (EFO) [@doi:10.1093/bioinformatics/btq099] term using the Stouffer's method.
This method takes into account the GWAS sample size for each trait and is calculated as $\sum w_i M_{ij} / \sqrt{\sum w_i^2}$, where $w_i$ is a weight and $M_{ij}$ is the $z$-score for gene $j$.
Second, we divided all $z$-scores for each trait by their sum to reduce the effect of highly polygenic traits.
This was done by calculating $M_{ij} / \sum M_{ij}$.
Finally, we projected this data matrix using Equation (@eq:proj), obtaining $\hat{\mathbf{M}}$ with $n$=3,752 traits and $l$=987 latent variables as the input of our clustering pipeline.


We used a consensus clustering approach to partition $\hat{\mathbf{M}}$ with $n$ traits into $k$ clusters.
This approach consists of two steps.
First, we generated an ensemble $\Pi$ with $r$ partitions of the dataset: $\Pi=\{\pi_1, \pi_2, \ldots, \pi_r\}$.
Second, we combined the ensemble into a consolidated solution.

$$
\pi^* = \mathrm{arg}\,\underset{\hat{\pi}}{\max} Q(\{ \lvert \mathcal{L}^i \lvert \phi(\hat{\pi}_{\mathcal{L}^i}, \pi_{i \mathcal{L}^i}) \mid i \in \{1,\ldots,r\} \}),
$$ {#eq:consensus:obj_func}

We used the adjusted Rand index (ARI) [@doi:10.1007/BF01908075] to measure the similarity between two partitions $\mathcal{L}^i$ and the median as a measure of central tendency.
To obtain the final partition $\pi^*$, we used the evidence accumulation clustering (EAC) paradigm [@doi:10.1109/TPAMI.2005.113].
This involved transforming $\mathcal{L}^i$ into a distance matrix $\mathbf{D}_{ij} = d_{ij} / r$, where $d_{ij}$ is the number of times traits $i$ and $j$ were grouped in different clusters across all $r$ partitions in $\Pi$.
We then applied a similarity-based clustering algorithm on $\mathbf{D}$ to derive $\pi^*$.


We used different algorithms to create a highly diverse set of partitions (see Figure @fig:clustering:design) since diversity is important [@doi:10.1016/j.ins.2016.04.027; @doi:10.1109/TPAMI.2011.84; @doi:10.1016/j.patcog.2014.04.005].
We used three data representations: raw data, its projection into the top 50 principal components, and an embedding learned by UMAP [@arxiv:1802.03426] with 50 components.
We applied five clustering algorithms: $k$-means [@Arthur2007], spectral clustering [@Ng2001], a Gaussian mixture model (GMM), hierarchical clustering, and DBSCAN [@Ester1996].
For $k$-means, spectral clustering and GMM, we specified a range of $k$ between 2 and $\sqrt{n} \approx 60$, and for each $k$ we generated five partitions with random seeds.
For hierarchical clustering, for each $k$, we generated four partitions with common linkage criteria (ward, complete, average, and single).
For DBSCAN, we combined different ranges for parameters $\epsilon$ (the maximum distance between two data points to be considered part of the same neighborhood) and *minPts* (the minimum number of data points in a neighborhood for a data point to be considered a core point), based on [@doi:10.1088/1755-1315/31/1/012012].
We used *minPts* values from 2 to 125, and determined a plausible range of $\epsilon$ values by observing the distribution of the mean distance of the *minPts*-nearest neighbors across all data points.
We resampled partitions generated by DBSCAN to ensure an equal representation of this algorithm in the ensemble, resulting in a final ensemble of 4,428 partitions of 3,752 traits.


Finally, we used spectral clustering on $\mathbf{D}$ to derive the final consensus partitions.
First, we transformed $\mathbf{D}$ into a similarity matrix by applying an RBF kernel $\mathrm{exp}(-\gamma \mathbf{D}^2)$ with four different values for $\gamma$ that we determined empirically to work best.
For each $k$ between 2 and 60, four consensus partitions were derived, and the one that maximized Equation (@eq:consensus:obj_func) was selected.
We further filtered this set of 59 solutions, keeping only those with an ensemble agreement larger than the 75th percentile (Supplementary Figure @fig:sup:clustering:agreement), leaving a total of 15 final consensus partitions shown in Figure @fig:clustering:tree.

Our clustering pipeline consists of several linear and nonlinear transformations, including Principal Component Analysis (PCA), Uniform Manifold Approximation and Projection (UMAP), and an ensemble transformation using the Ensemble Adaptive Clustering (EAC) paradigm (distance matrix $\mathbf{D}$).
To interpret the results, we used a supervised learning approach to detect which gene modules/Latent Variables (LVs) were most important for each cluster of traits (Figure {@fig:clustering:design}b).
We trained a decision tree model using each cluster as labels and the projected data $\hat{\mathbf{M}}$ as the training samples.
We selected the LV in the root node of the trained model only if its threshold was positive and larger than one standard deviation.
We repeated this procedure 20 times to extract the top 20 LVs that best discriminated traits in a cluster from the rest.

We performed several analyses to verify that the clustering results detected by this pipeline were real.
We tested this hypothesis under a null model, which assumed no structure in the data (see Supplementary Note 2).


### CRISPR-Cas9 screening {#sec:methods:crispr}

Cell culture was performed using HepG2 cells from ATCC (ATCC® HB-8065™).
They were kept in Eagle's Minimum Essential Medium (EMEM, Cat.
112-018-101, Quality Biology) supplemented with 10% Fetal Bovine Serum (FBS, Gibco, Cat.16000-044) and 1% Pen/Strep (Gibco, Cat.15140-122).
The cells were incubated at 37°C in a humidity-controlled incubator with 5% CO2 and kept at a density not exceeding 80% confluency.

<!--
ERROR: the paragraph below could not be revised with the AI model due to the following error:

The AI model returned an empty string ('')
-->
**Genome-wide lentiviral pooled CRISPR-Cas9 library.** 3rd lentiviral generation, Broad GPP genome-wide Human Brunello CRISPR knockout Pooled library was provided by David Root and John Doench from Addgene (Cat.
73179-LV), and was used for HepG2 cell transduction.
It consists of 76,441 sgRNAs, and targets 19,114 genes in the human genome with an average of 4 sgRNAs per gene.
Each 20nt sgRNA cassette was inserted into the lentiCRIS-PRv2 backbone between U6 promoter and gRNA scaffold.
Through cell transduction, the lentiviral vectors which encode Cas9 were used to deliver the sgRNA cassette containing plasmids into cells during cell replication.
Unsuccessful transduced cells were excluded through puromycin selection.

No-spin lentiviral transduction was used to determine the titer of the virus.
Cells were seeded in a Collagen-I coated 6-well plate with 8ug/ml polybrene and different titrated virus volumes (e.g., 0, 50, 100, 200, 250, and 400ul).
16-18 hours post-transduction, the virus/polybrene-containing media was removed and the cells were washed twice with 1x DPBS and replaced with fresh EMEM.
At 24 hours, the cells were trypsinized and diluted (e.g.,1:10).
60 hours post-transduction, the cell media in each well was replaced with fresh EMEM and 2ug/ml of puromycin was added to one well out of the pair.
2-5 days after puromycin selection, the cell numbers with/without puromycin selection within each pair were compared to obtain the Percentage of Infection (PI%).
To achieve an MOI of ~0.3, a volume of virus (120ul) yielding 30-40% of transduction efficiency was chosen for further large-scale viral transduction.

We transduced ~200 million HepG2 cells with a lentiviral Brunello CRISPR Knockout Pooled Library.
This was done to ensure that at least 500 cells per sgRNA were covered and that 95% of the infected cells received only one viral particle per cell.
The transduction was done using 8ug/ml of polybrene, with 120ul of virus added to each experimental well.
After 18 hours, the virus/PB mix medium was removed, and the cells were collected, counted, and pooled into T175 flasks.
After 60 hours, 2ug/ml of puromycin was added to each flask, and the mediums were changed every two days with fresh EMEM and topped with 2ug/ml of puromycin.
Seven days later, the cells were collected, pooled, counted, and replated.

Cells were stained with a fluorescent dye (LipidSpotTM 488, Biotium, Cat.
70065-T) 9 days after puromycin selection.
20-30 million cells were collected as Unsorted Control, while the rest (approximately 200 million) were kept in 100mm dishes and incubated with a 1:100 dilution of the dye in DPBS at 37°C for 30 minutes.
Cell images were captured through a fluorescent microscope (EVOS) for GFP signal detection (Figure @fig:sup:crispr:fig1).
The dry pellet from the Unsorted Control was kept at -80°C for further genomic DNA isolation.

Cells were collected in 50ml tubes and spun at 500 x g for 5 minutes at 4°C.
After a DPBS wash, the cell pellets were resuspended in FACS Sorting Buffer (1x DPBS without Ca2+/Mg2+, 2.5mM EDTA, 25mM HEPES, 1% BSA, filtered and kept at 4°C).
Cells were then passed through a cell strainer (Falcon, Cat.
352235) and kept on ice, protected from light.
Using a 100 μm nozzle, 20% of GFP-High and GFP-Low cells (Figure @fig:sup:crispr:fig2) were sorted on FACSJazz and collected into 15ml tubes.
After sorting, the cells were immediately spun down and the pellets were stored at -80°C for further genomic DNA isolation.

Genomic DNA was isolated from three conditions (Un-Sorted Control, lentiV2 GFP-High, and lentiV2 GFP-Low) using the QIAamp DNA Blood Mini Kit (Qiagen, Cat.51104).
The quality and quantity of the gDNA was assessed using UV Spectroscopy (Nanodrop).
A total of 80-160ug of gDNA was isolated for each condition.
PCR was used to confirm the presence of the sgRNA cassette and lentiviral specific transgene in the isolated gDNA (Figure @fig:sup:crispr:fig3).

Illumina libraries were generated and sequenced to amplify a fragment containing the sgRNA cassette.
Primers (P5/P7) were adapted from the Broad Institute protocol (Figure @fig:sup:crispr:table1), with a 0-8nt stagger sequence included in the P5 primer and an 8bp uniquely barcoded sequence in the P7 primer.
The primers were synthesized by Integrated DNA Technologies (IDT) and purified using PAGE.
32 PCR reactions (100ul each) were set up for each condition, containing 5ug of gDNA and 5ul of each 10uM P5 and P7 primer, and ExTaq DNA Polymerase (TaKaRa, Cat.
RR001A).
The PCR Thermal Cycler Parameters were set as Initial at 95oC for 1min; followed by 24 cycles of Denaturation at 94oC for 30 seconds, Annealing at 52.5oC for 30 seconds, Extension at 72oC for 30 seconds, and a final Elongation at 72oC for 10 minutes.
The expected PCR products were 285bp-293bp in size (Figure @fig:sup:crispr:fig4 A).
The PCR products within the same condition were pooled, purified using SPRIselect beads (Beckman Coulter, Cat.
B23318), quantitated on Qubit, and the quality of the library was analyzed on Bio-analyzer using High Sensitivity DNA Chip (Figure @fig:sup:crispr:fig4 B).
Finally, the Illumina library samples were sequenced on Nova-seq 6000, with a 20% PhiX control v3 library spike-in.


### Code and data availability

We used the gene co-expression network from the Human Protein Atlas (HPA) to identify gene clusters associated with a given phenotype.
We then used functional genomics data to identify genes that are associated with the phenotype, and we used clustering algorithms to identify clusters of complex traits.
Finally, we used the identified clusters to predict therapeutic targets and drug repurposing opportunities.
