## Methods and materials {#sec:methods}

PhenoPLIER is a framework combining different computational approaches to integrate gene-trait associations, drug-induced transcriptional responses, and groups of functionally-related genes (referred to as gene modules or latent variables/LVs).
PrediXcan family of methods are used to compute gene-trait associations, while MultiPLIER models are applied on large gene expression compendia to infer latent variables.
PhenoPLIER provides: 1) a regression model to compute an LV-trait association, 2) a consensus clustering approach applied to the latent space to learn shared and distinct transcriptomic properties between traits, and 3) an interpretable, LV-based drug repurposing framework.
Details of these methods are provided below.


### The PrediXcan family of methods for gene-based associations {#sec:methods:predixcan}

We used two gene-based statistical approaches from the PrediXcan family of methods [@doi:10.1038/ng.3367], Summary-PrediXcan (S-PrediXcan) [@doi:10.1038/s41467-018-03621-1] and Summary-MultiXcan (S-MultiXcan) [@doi:10.1371/journal.pgen.1007889], which we refer to collectively as TWAS (transcription-wide association studies).
S-PrediXcan calculates the association between a trait and a gene's predicted expression in a single tissue, while S-MultiXcan calculates the joint association between a gene's predicted expression in all tissues and a trait.
Both approaches require only GWAS summary statistics, rather than individual-level genotype and phenotype data.

We provide the following details about the TWAS methods necessary to explain our regression framework later (see the referenced articles for more information).
We refer to $\mathbf{y}$ as a vector of traits for $n$ individuals, which is centered in order to avoid the need for an intercept.
$\mathbf{\tilde{t}}_l$ is the gene's predicted expression for all individuals in tissue $l$, with $X_a$ being the genotype of SNP $a$ and $w_{a}$ its weight in the tissue prediction model $l$.
Lastly, $\mathbf{t}_l$ is the standardized version of $\mathbf{\tilde{t}}_l$, with a mean of zero and a standard deviation of one.

and a subset of the genes on multiple tissues using the multivariate model.
We applied S-PrediXcan to the gene expression data from the GTEx project [@doi:10.1126/science.1243485] to predict genetic associations with the traits of interest.

We used S-PrediXcan to project genetic associations through gene expression patterns.
This method, based on the PrediXcan model, uses gene expression data from the GTEx project to predict associations between genetic variations and traits of interest.
The Predi

$$
\mathbf{y} = \mathbf{t}_l \gamma_l + \bm{\epsilon}_l,
$$ {#eq:predixcan}

of the gene in the same tissue.

We assess the significance of the genetic association by computing the $z$-score $\hat{z}_{l}$ for a gene's tissue model $l$.
This $z$-score is equal to the estimated effect size or regression coefficient $\hat{\gamma}_l$ divided by the standard error of $\hat{\gamma}_l$.
PrediXcan requires individual-level data to compute the $z$-score, while S-PrediXcan approximates it using only GWAS summary statistics and the gene expression in the same tissue.

$$
\hat{z}_{l} \approx \sum_{a \in model_{l}} w_a^l \frac{\hat{\sigma}_a}{\hat{\sigma}_l} \frac{\hat{\beta}_a}{\mathrm{se}(\hat{\beta}_a)},
$$ {#eq:spredixcan}

We used the TWAS methods of S-PrediXcan to estimate the genetic associations between SNPs and gene expression levels in the GTEx v8 panel.
Specifically, we estimated the genotype variances ($\hat{\sigma}_a$) and covariances ($\hat{\sigma}_l$) of SNPs and the predicted expression of genes in tissue $l$, as well as the estimated effect size of SNPs ($\hat{\beta}_a$).
Since S-PrediXcan provides tissue-specific direction of effects (i.e.
whether a higher or lower predicted expression of a gene confers more or less disease risk), we used the $z$-scores in our drug repurposing approach (described below).

, which is a measure of the association between a gene and a trait.
S-MultiXcan reduces the computational burden of MultiXcan by using a summary-level association statistic.

S-MultiXcan is an alternative to PrediXcan and is more powerful in detecting gene-trait associations.
It does not provide the direction of effects, but its main output is a measure of the association between a gene and a trait: the $p$-value (obtained with an F-test).
S-MultiXcan reduces the computational burden of MultiXcan by using a summary-level association statistic.

$$
\begin{split}
\mathbf{y} & = \sum_{l=1}^{p} \mathbf{t}_l g_l + \mathbf{e} \\
 & = \mathbf{T} \mathbf{g} + \mathbf{e},
\end{split}
$$ {#eq:multixcan}

a chi-square test.

MultiXcan uses the principal components (PCs) of a matrix $\mathbf{T}$ with $p$ columns $\mathbf{t}_l$ to avoid collinearity issues.
This matrix is used to estimate the effect size $\hat{g}_l$ for the predicted gene expression in each tissue $l$, and thus $\mathbf{\hat{g}}$ is a vector with $p$ estimated effect sizes.
S-MultiXcan derives the joint regression estimates (effect sizes and their variances) using the marginal estimates from S-PrediXcan.
Under the null hypothesis of no association, the significance of the association in S-MultiXcan is estimated with a chi-square test, using the formula $\mathbf{\hat{g}}^{\top} \frac{\mathbf{T}^{\top}\mathbf{T}}{\sigma_{e}^{2}} \mathbf{\hat{g}} \sim \chi_{p}^{2}$, where $\mathbf{e}$ are the error terms with variance $\sigma_{e}^{2}$.

$$
\begin{split}
\frac{\mathbf{\hat{g}}^{\top} (\mathbf{T}^{\top}\mathbf{T}) \mathbf{\hat{g}}}{\sigma_{e}^{2}} & \approx \bm{\hat{\gamma}}^{\top} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \left(\frac{\mathbf{T}^{\top} \mathbf{T}}{n-1}\right)^{-1} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \bm{\hat{\gamma}} \\
 & = \mathbf{\hat{z}}^{\top} Cor(\mathbf{T})^{-1} \mathbf{\hat{z}},
\end{split}
$$ {#eq:smultixcan}

S-MultiXcan is used to calculate $z$-scores for each gene in a given tissue.
This is done by computing the pseudo-inverse of the autocorrelation matrix of the tissue, $\mathbf{T}^{\top}\mathbf{T}$, and taking into account the conservative approximation $\sigma_{e}^{2} \approx \sigma_{\epsilon}^{2}$.
This means that the variance of the error terms in the joint regression is approximately equal to the residual variance of the marginal regressions.
Additionally, the global genotype covariance matrix is used to estimate the correlation matrix, while tissue-specific genotype covariances are used to approximate marginal $z$-scores.
Results from S-MultiXcan were used for the LV-based regression model and the cluster analyses of traits.
It should be noted that the results are not perfectly correlated across genes.
This difference is important for computing the gene-gene correlation matrix.


### TWAS resources {#sec:methods:twas}

We used two large TWAS resources from European ancestries for discovery and replication.
PhenomeXcan, our discovery cohort, provides results on 4,091 traits across different categories.
The included GWAS summary statistics were used to compute gene-based associations with the PrediXcan family of methods, and a posterior probability of colocalization between GWAS loci and *cis*-eQTL with fastENLOC.
The S-PrediXcan results (Equation (@eq:spredixcan)) across $q$ traits and $m$ genes in tissue $t$ were represented as $\mathbf{M}^{t} \in \mathbb{R}^{q \times m}$ and used in our LV-based drug repurposing framework.
The S-MultiXcan results (22,515 gene associations across 4,091 traits) were used in our LV-based regression framework and cluster analyses of traits.
For the cluster analyses, we converted the $p$-values to $z$-scores using the probit function.
Higher $z$-scores correspond to stronger associations.
Further details can be found in Supplementary File 1.

We used the eMERGE cohort to apply our TWAS methods to 309 phecodes across different categories.
More information about the traits is available in [@doi:10.1101/2021.10.21.21265225].
We then used the results to replicate the associations found with our LV-based regression framework in PhenomeXcan.


### MultiPLIER and Pathway-level information extractor (PLIER) {#sec:methods:multiplier}

We applied MultiPLIER to the recount2 dataset to extract patterns of co-expressed genes.
MultiPLIER is a pathway-level information extractor method (PLIER) that uses unsupervised learning and prior knowledge (canonical pathways) to reduce technical noise.
The approach uses a matrix factorization approach, which deconvolutes gene expression data into a set of latent variables (LVs).
We used MultiPLIER to reduce the dimensionality in recount2 to 987 LVs.

the following objective function:

We used the PLIER algorithm to analyze a gene expression dataset with $m$ genes and $c$ experimental conditions.
The prior knowledge matrix $\mathbf{C} \in \{0,1\}^{m \times p}$ was used to indicate if a gene belonged to one of the $p$ MSigDB pathways [@doi:10.1016/j.cels.2015.12.004].
The PLIER algorithm minimizes an objective function to find $\mathbf{U}$, $\mathbf{Z}$, and $\mathbf{B}$.

$$
||\mathbf{Y} - \mathbf{Z}\mathbf{B}||^{2}_{F} + \lambda_1 ||\mathbf{Z} - \mathbf{C}\mathbf{U}||^{2}_{F} + \lambda_2 ||\mathbf{B}||^{2}_{F} + \lambda_3 ||\mathbf{U}||_{L^1}
$$ {#eq:met:plier_func}

We used a model with the following parameters: $\mathbf{U}>0$, $\mathbf{Z}>0$, where $\mathbf{Z}$ is a low-dimensional representation of the gene space.
$\mathbf{Z}^{m \times l}$ are the gene loadings with $l$ latent variables, $\mathbf{B}^{l \times c}$ is the latent space for $c$ conditions, $\mathbf{U}^{p \times l}$ specifies which of the $p$ prior-information pathways in $\mathbf{C}$ are represented for each latent variable.
$\lambda_i$ are different regularization parameters used in the training step.
The aim of this model is for each latent variable to align as much as possible to prior knowledge and might represent either a known or novel gene module (i.e., a meaningful biological pattern) or noise.

the linear model $\mathbf{M}_p = \mathbf{M} \mathbf{A}$, where $\mathbf{M}_p$ is the projected TWAS matrix and $\mathbf{A}$ is the module loading matrix.

To apply drug repurposing and cluster analysis, we projected gene-trait and gene-drug associations into a low-dimensional gene module space.
For example, we used a linear model to project TWAS associations (either from S-PrediXcan or S-MultiXcan) into this space.
This model was represented by the equation $\mathbf{M}_p = \mathbf{M} \mathbf{A}

$$
\hat{\mathbf{M}} = (\mathbf{Z}^{\top} \mathbf{Z} + \lambda_{2} \mathbf{I})^{-1} \mathbf{Z}^{\top} \mathbf{M},
$$ {#eq:proj}

We used a matrix $\hat{\mathbf{M}}^{l \times q}$ to represent traits in terms of gene modules instead of single genes.
Later on, we applied the same approach to project drug-induced transcriptional profiles from the LINCS L1000 database, resulting in a representation of drugs using gene modules.


### Regression model for LV-trait associations {#sec:methods:reg}

to each gene-trait association and compared the predictive power of the top-weighted genes against a permutation-based null model.

We adapted the gene-set analysis framework from MAGMA [@doi:10.1371/journal.pcbi.1004219] to TWAS.
We used a competitive test to predict gene-trait associations by utilizing gene weights from an LV.
Specifically, we tested whether the top-weighted genes for an LV are more strongly associated with the phenotype than other genes with relatively small or zero weights.
To do this, we fit the model to each gene-trait association and compared the predictive power of the top-weighted genes against a null model based on permutations.

$$
\mathbf{m}=\beta_{0} + \mathbf{s} \beta_{s} + \sum_{i} \mathbf{x}_{i} \beta_{i} + \bm{\epsilon},
$$ {#eq:reg:model}

The Methods section of the paper 'Projecting genetic associations through gene expression patterns highlights disease etiology and drug mechanisms' includes a vector of S-MultiXcan gene $p$-values for a trait, $\mathbf{m}$, with a $-log_{10}$ transformation.
A binary indicator vector, $\mathbf{s}$, is used with $s_{\ell}=1$ for the top 1% of genes with the largest loadings for the latent variable $\ell$.
A gene property, $\mathbf{x}_{i}$, is used as a covariate, and effect sizes, $\beta$, are included with $\beta_{0}$ as the intercept.
Additionally, a vector of error terms, $\bm{\epsilon}$, has a multivariate normal distribution (MVN) with a matrix of gene correlations, $\mathbf{R}$, as the variance.

We tested the null hypothesis that the difference in trait associations between genes within and outside of latent variable $\ell$ is zero, against the one-sided hypothesis that the difference is greater than zero.
To do this, we followed the MAGMA framework and used two gene properties as covariates: the number of PCs retained in S-MultiXcan (gene size) and the ratio of the number of PCs to the number of tissues available (gene density).

We used a generalized least squares approach to account for correlations between the error terms in our model.
We estimated the gene-gene correlation matrix $\mathbf{R}$ by computing the correlations between the model sum of squares (SSM) for each pair of genes under the null hypothesis of no association.
This was done using the individual-level MultiXcan model (Equation (@eq:multixcan)), which projects the predicted expression matrix $\mathbf{T}_{i} \in \mathbb{R}^{n \times p_i}$ of a gene $i$ across $p_i$ tissues into its top $k_i$ PCs, resulting in matrix $\mathbf{P}_{i} \in \mathbb{R}^{n \times k_i}$.
Under the null hypothesis of no association, the covariances between the SSM of genes $i$ and $j$ is given by $2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})$, and the standard deviations of each SSM are given by $\sqrt{2 \times k_{i}} \times (n - 1)$.
Thus, the correlation between the SSMs for genes $i$ and $j$ can be written as follows:

$$
\begin{split}
\mathbf{R}_{ij} & = \frac{2 \times \mathrm{Tr}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}} \times (n - 1)^2} \\
& = \frac{2 \times \mathrm{Tr}(Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \times Cor(\mathbf{P}_{j}, \mathbf{P}_{i}))}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}}},
\end{split}
$$ {#eq:reg:r}

This paragraph can be revised as follows:

The cross-correlation matrix between PCs is given by the trace of a matrix, where the columns are standardized.
This matrix is represented by $Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \in \mathbb{R}^{k_i \times k_j}$.

$$
\begin{split}
Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) & = Cor(\mathbf{T}_{i} \mathbf{V}_{i}^{\top} \mathrm{diag}(\lambda_i)^{-1/2}, \mathbf{T}_{j} \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2}) \\
& = \mathrm{diag}(\lambda_i)^{-1/2} \mathbf{V}_{i} (\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1}) \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2},
\end{split}
$$ {#eq:reg:cor_pp}

as

We used [@doi:10.1371/journal.pgen.1007889] to estimate the correlation of predicted expression levels for genes $i$ in tissue $k$ and gene $j$ in tissue $l$.
This was done by calculating the cross-correlation matrix between the predicted expression levels of genes $i$ and $j$, denoted as $\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1} \in \mathbb{R}^{p_i \times p_j}$.
We then obtained the eigenvectors and eigenvalues of $\mathbf{T}_{i}$, denoted as columns of $\mathbf{V}_{i}$ and scalars $\lambda_i$ respectively.
To reduce the complexity of the model, S-MultiXcan kept only the top eigenvectors using a condition number threshold of $\frac{\max(\lambda_i)}{\lambda_i} < 30$.

$$
\begin{split}
\frac{(\mathbf{T}_{i}^{\top} \mathbf{T}_{j})_{kl}}{n-1} & = Cor(\mathbf{t}_k^i, \mathbf{t}_l^j) \\
 & = \frac{ Cov(\mathbf{t}_k, \mathbf{t}_l) } { \sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ Cov(\sum_{a \in \mathrm{model}_k} w_a^k X_a, \sum_{b \in \mathrm{model}_l} w_b^l X_b) }  {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l} w_a^k w_b^l Cov(X_a, X_b)} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
 & = \frac{ \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l} w_a^k w_b^l \Gamma_{ab}} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} },
\end{split}
$$ {#eq:reg:corr_genes}

We use the genotype covariance matrix $\Gamma$ from the GTEx v8 reference panel to predict gene expression values in tissue $k$.
The variance of the predicted expression values of gene $i$ in tissue $k$ is estimated as [@doi:10.1038/s41467-018-03621-1]: 
For each SNP $a$, we calculate a weight $w_a^k$ which is used to predict the gene expression.
This weight is based on the genotype $X_a$ of SNP $a$ and the genotype covariance matrix $\Gamma$.

$$
\begin{split}
\widehat{\mathrm{var}}(\mathbf{t}_k^i) & = (\mathbf{W}^k)^\top \Gamma^k \mathbf{W}^k \\
 & = \sum_{a \in \mathrm{model}_k \\ b \in \mathrm{model}_k} w_a^k w_b^k \Gamma_{ab}^k.
\end{split}
$$ {#eq:reg:var_gene}

We used the MultiXcan regression model (Equation (@eq:multixcan)) to approximate gene correlations in S-MultiXcan.
To account for the simplifying assumptions and different genotype covariance matrices used in S-PrediXcan (Equation (@eq:spredixcan)), we used a submatrix $\mathbf{R}_{\ell}$ corresponding to genes that are part of LV $\ell$ only (top 1% of genes) instead of the entire matrix $\mathbf{R}$.
Our simulations ([Supplementary Note 1](#sm:reg:null_sim)) show that the model is approximately well-calibrated and can correct for LVs with adjacent and highly correlated genes at the top (e.g., Figure @fig:reg:nulls:qqplot:lv234).
Additionally, it can detect LVs associated with relevant traits (Figure @fig:lv246 and Table @tbl:sup:phenomexcan_assocs:lv246) which are replicated in a different cohort (Table @tbl:sup:emerge_assocs:lv246).

In the case of eMERGE, we used a single correlation matrix for each tissue model.

We computed the correlation matrix for each dataset by considering only the SNPs present in the GWAS used as input for TWAS approaches, as well as the tissue models present in the S-PrediXcan results.
This was done to ensure more accurate correlation estimates [@doi:10.1371/journal.pgen.1007889].
For PhenomeXcan, we used a single correlation matrix for the UK Biobank GWAS (4,049) since they were obtained using the same pipeline and included the same set of SNPs.
For the other traits, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.
For eMERGE, we used a single correlation matrix for each tissue model.

We ran our regression model across 4,091 traits in PhenomeXcan and 309 phecodes in eMERGE.
The $p$-values were adjusted using the Benjamini-Hochberg procedure.
In total, 987 latent variables were analyzed.


### LV-based drug repurposing approach {#sec:methods:drug}

We compared our LV-based method for drug-disease prediction with a single-gene approach previously used for psychiatric traits [@doi:10.1038/nn.4618].
This single-gene method computed a drug-disease score by multiplying a set of signed $z$-scores from tissue $t$, $\mathbf{M}^t$, with another set of signed $z$-scores from LINCS L1000 [@doi:10.1016/j.cell.2017.10.049], $\mathbf{L}^{c \times m}$ (for $c$ compounds).
$\mathbf{M}^t$ contains information about gene associations with a trait, and $\mathbf{L}$ indicates whether a drug increases or decreases the expression of a gene.
We multiplied these matrices to obtain a score for each drug-disease pair, $\mathbf{D}^{t,k}=-1 \cdot \mathbf{M}^{t,k} \mathbf{L}^\top$.
The number of most significant gene associations in $\mathbf{M}^t$ for each trait was either all genes or the top 50, 100, 250, and 500, and we averaged the score ranks across all $k$.
Then, for each drug-disease pair, we took the maximum prediction score across all tissues: $\mathbf{D}_{ij} = \max \{ \mathbf{D}_{ij}^t \mid \forall t \}$.


For the Latent Variable (LV)-based approach, we projected the gene expression matrix $\mathbf{M}^{t}$ and the genetic association matrix $\mathbf{L}$ into the gene module latent space using Equation (@eq:proj).
This resulted in $\hat{\mathbf{M}}^t$ and $\hat{\mathbf{L}}^{l \times c}$, respectively.
We then calculated $\mathbf{D}^{t,k}=-1 \cdot \hat{\mathbf{L}}^{\top} \hat{\mathbf{M}}^{t,k}$, where $k$ could be all LVs or the top 5, 10, 25 and 50 (due to the lower number of LVs compared to genes).


We then used a linear regression-based method to project genetic associations into gene expression patterns in a tissue-specific manner [@doi:10.1093/nar/gky1032].

To map the PhenomeXcan traits to the Disease Ontology IDs (DOID) - the gold standard of drug-disease medical indications - we used the Experimental Factor Ontology and a linear regression-based method.
This method allowed us to project genetic associations into tissue-specific gene expression patterns [@doi:10.1093/nar/gky1032].
For the mapping, we used a GitHub repository [@url:https://github.com/EBISPOT/EFO-UKB-mappings].


### Consensus clustering of traits {#sec:methods:clustering}

We preprocessed the S-MultiXcan results before the cluster analysis.
First, we combined $z$-scores from traits that mapped to the same Experimental Factor Ontology (EFO) term using the Stouffer's method.
This involved calculating a weight based on the GWAS sample size for each trait and combining results for each gene.
Second, we divided all $z$-scores for each trait by their sum to reduce the effect of highly polygenic traits.
Finally, we projected this data matrix using a specified equation, obtaining a matrix with 3,752 traits and 987 LVs as the input of our clustering pipeline.


We partitioned $\hat{\mathbf{M}}$ into $k$ clusters, represented as a label vector $\pi \in \mathbb{N}^n$.
We used consensus clustering, a two-step approach that first generated an ensemble $\Pi$ with $r$ partitions of the dataset: $\Pi=\{\pi_1, \pi_2, \ldots, \pi_r\}$, and then combined the ensemble into a consolidated solution.

$$
\pi^* = \mathrm{arg}\,\underset{\hat{\pi}}{\max} Q(\{ \lvert \mathcal{L}^i \lvert \phi(\hat{\pi}_{\mathcal{L}^i}, \pi_{i \mathcal{L}^i}) \mid i \in \{1,\ldots,r\} \}),
$$ {#eq:consensus:obj_func}

We used the adjusted Rand index (ARI) [@doi:10.1007/BF01908075] and the median as measures of central tendency to obtain the consensus partition $\pi^*$.
To do this, we defined a consensus function $\Gamma\colon \mathbb{N}^{n \times r} \to \mathbb{N}^n$ with $\Pi$ as the input.
This consensus function was based on the evidence accumulation clustering (EAC) paradigm [@doi:10.1109/TPAMI.2005.113], where $\Pi$ was first transformed into a distance matrix $\mathbf{D}_{ij} = d_{ij} / r$, where $d_{ij}$ is the number of times traits $i$ and $j$ were grouped in different clusters across all $r$ partitions in $\Pi$.
Then, $\Gamma$ was any similarity-based clustering algorithm, which was applied on $\mathbf{D}$ to derive the final partition $\pi^*$.


We used different algorithms to generate a highly diverse set of partitions (see Figure @fig:clustering:design) since diversity is an important property for ensembles [@doi:10.1016/j.ins.2016.04.027; @doi:10.1109/TPAMI.2011.84; @doi:10.1016/j.patcog.2014.04.005].
We used three data representations: the raw dataset, its projection into the top 50 principal components, and the embedding learned by UMAP [@arxiv:1802.03426] using 50 components.
We applied five clustering algorithms: $k$-means [@Arthur2007], spectral clustering [@Ng2001], a Gaussian mixture model (GMM), hierarchical clustering, and DBSCAN [@Ester1996].
For $k$-means, spectral clustering and GMM, we specified a range of $k$ between 2 and $\sqrt{n} \approx 60$, and for each $k$ we generated five partitions using random seeds.
For hierarchical clustering, for each $k$, we generated four partitions using common linkage criteria: ward, complete, average and single.
For DBSCAN, we combined different ranges for parameters $\epsilon$ (the maximum distance between two data points to be considered part of the same neighborhood) and *minPts* (the minimum number of data points in a neighborhood for a data point to be considered a core point), based on the procedure in [@doi:10.1088/1755-1315/31/1/012012].
We used *minPts* values from 2 to 125, and determined a plausible range of $\epsilon$ values by observing the distribution of the mean distance of the *minPts*-nearest neighbors across all data points.
We resampled partitions generated by DBSCAN to ensure an equal representation of this algorithm in the ensemble.
This procedure generated a final ensemble of 4,428 partitions of 3,752 traits.


Finally, we used spectral clustering to derive the final consensus partitions.
We transformed $\mathbf{D}$ into a similarity matrix by applying an RBF kernel $\mathrm{exp}(-\gamma \mathbf{D}^2)$ with four different values of $\gamma$ that we empirically determined to work best.
We then selected the partition that maximized Equation (@eq:consensus:obj_func) for each $k$ between 2 and 60.
We further filtered this set of 59 solutions to keep only those with an ensemble agreement larger than the 75th percentile (Supplementary Figure @fig:sup:clustering:agreement), leaving a total of 15 final consensus partitions shown in Figure @fig:clustering:tree.

Our clustering pipeline includes several linear and nonlinear transformations, such as PCA, UMAP and the ensemble transformation using the EAC paradigm (distance matrix $\mathbf{D}$).
To better interpret the results, we used a supervised learning approach to detect which gene modules/LVs are most important for each cluster of traits (Figure {@fig:clustering:design}b).
We trained a decision tree model using each of the clusters as labels and the projected data $\hat{\mathbf{M}}$ as the training samples.
We built a set of binary labels with the current cluster's traits as the positive class and the rest of the traits as the negative class.
We selected the LV in the root node of the trained model if its threshold was positive and larger than one standard deviation.
We then removed this LV from $\hat{\mathbf{M}}$ and repeated this procedure 20 times to extract the top 20 LVs that better discriminate traits in a cluster from the rest.

We conducted several analyses to ensure that the clustering results obtained by our pipeline were reliable.
These analyses were performed under the null hypothesis of no structure existing in the data and are described in Supplementary Note 2.


### CRISPR-Cas9 screening {#sec:methods:crispr}

HepG2 cells were obtained from ATCC (ATCC® HB-8065™) and maintained in Eagle's Minimum Essential Medium with L-Glutamine (EMEM, Cat.
112-018-101, Quality Biology) supplemented with 10% Fetal Bovine Serum (FBS, Gibco, Cat.16000-044) and 1% Pen/Strep (Gibco, Cat.15140-122).
The cells were kept in a humidity-controlled incubator with 5% CO2 at 37oC, and the density was not allowed to exceed 80% confluency.

<!--
ERROR: the paragraph below could not be revised with the AI model due to the following error:

The AI model returned an empty string ('')
-->
**Genome-wide lentiviral pooled CRISPR-Cas9 library.** 3rd lentiviral generation, Broad GPP genome-wide Human Brunello CRISPR knockout Pooled library was provided by David Root and John Doench from Addgene (Cat.
73179-LV), and was used for HepG2 cell transduction.
It consists of 76,441 sgRNAs, and targets 19,114 genes in the human genome with an average of 4 sgRNAs per gene.
Each 20nt sgRNA cassette was inserted into the lentiCRIS-PRv2 backbone between U6 promoter and gRNA scaffold.
Through cell transduction, the lentiviral vectors which encode Cas9 were used to deliver the sgRNA cassette containing plasmids into cells during cell replication.
Unsuccessful transduced cells were excluded through puromycin selection.

No-spin lentiviral transduction was used to determine the titer of the virus.
Cells were seeded in 6-well plates coated with Collagen-I in the presence of 8ug/ml polybrene and different volumes of the virus (e.g., 0, 50, 100, 200, 250, and 400ul) were assigned to each well.
The cells were then incubated with EMEM complete media for 16-18 hours.
After this, the virus/polybrene-containing media was removed from each well and the cells were washed twice with 1x DPBS and replaced with fresh EMEM.
24 hours later, the cells were trypsinized, diluted (e.g., 1:10) and seeded in pairs of wells of 6-well plates.
60 hours post-transduction, the cell media in each well was replaced with fresh EMEM and 2ug/ml of puromycin (Gibco, Cat.
A1113803) was added to one well out of the pair.
2-5 days later, the cell numbers with/without puromycin selection within each pair were compared to obtain the percentage of infection (PI%).
According to Poisson's distribution theory, an MOI of ~0.35-0.70 (corresponding to a PI% of 30-50%) was chosen for further large-scale viral transduction, as this would result in around 95% of infected cells having only one copy of the virus.

In order to assess gene expression patterns, lentiviral transduction was performed in HepG2 cells using a Brunello CRISPR knockout pooled library.
Approximately 200 million cells were seeded in 14 6-well plates along with 8ug/ml of polybrene and a volume of 120ul of the virus was added to each experimental well.
18 hours post-transduction, the virus/PB mix medium was removed and the cells were collected, counted, and pooled into T175 flasks.
At 60 hours post-transduction, 2ug/ml of puromycin was added to each flask.
The mediums were changed every two days with fresh EMEM and topped with 2ug/ml puromycin.
Seven days after puromycin selection, the cells were collected, pooled, counted, and replated to assess gene expression patterns.

Cells were assigned to two groups nine days after puromycin selection.
For the Unsorted Control, approximately 20-30 million cells were collected and the cell pellet was spun down at 500 x g for 5 minutes at 4oC.
The dry pellet was then kept at -80oC for further genomic DNA isolation.
The remaining cells (approximately 200 million) were kept in 100 mm dishes and stained with the fluorescent dye LipidSpot 488 (Biotium, Cat.
70065-T).
The dye was diluted to 1:100 with DPBS and 4 ml of the staining solution was used for each dish.
The cells were then incubated at 37oC for 30 minutes and their images were captured through a fluorescent microscope EVOS for GFP signal detection (Figure @fig:sup:crispr:fig1).

Cells were collected into 50mL tubes, and spun at 500xg for 5 minutes at 4°C.
After washing with DPBS, the cell pellets were resuspended in FACS Sorting Buffer (1x DPBS without Ca2+/Mg2+, 2.5mM EDTA, 25mM HEPES, 1% BSA; filtered and stored at 4°C).
The cell solution was then filtered through a cell strainer (Falcon, Cat.
352235) and kept on ice, away from light.
Cells were sorted using Fluorescence-activated cell sorting (FACSJazz) with a 100μm nozzle, with ~20% of each GFP-High and GFP-Low (Figure @fig:sup:crispr:fig2) collected into 15mL tubes.
After sorting, cells were immediately spun down and the pellets were stored at -80°C for further genomic DNA isolation.

Genomic DNA was isolated from three conditions (Un-Sorted Control, lentiV2 GFP-High, and lentiV2 GFP-Low) using the QIAamp DNA Blood Mini Kit (Qiagen, Cat.51104), and then verified with UV Spectroscopy (Nanodrop) to measure the quality and quantity.
A total of 80-160ug of gDNA was isolated from each condition.
To confirm the presence of the sgRNA cassette and lentiviral specific transgene in the isolated gDNA, PCR was performed (Figure @fig:sup:crispr:fig3).

Illumina libraries were generated and sequenced to obtain the genetic associations.
PCR reactions were set up for each condition, consisting of 5 μg of gDNA, 5 μL of 10 μM P5 and P7 primers, and ExTaq DNA Polymerase.
The thermal cycling parameters were set to 95°C for 1 min, followed by 24 cycles of 94°C for 30 s, 52.5°C for 30 s, and 72°C for 30 s, with a final elongation at 72°C for 10 min.
The expected PCR product size was 285-293 bp (Figure @fig:sup:crispr:fig4 A).
The PCR products within each condition were pooled, purified with SPRIselect beads, and quantified with Qubit.
The quality of the library was analyzed on a High Sensitivity DNA Chip (Figure @fig:sup:crispr:fig4 B).
Finally, the Illumina library samples were sequenced on Nova-seq 6000, with a 20% PhiX control v3 library spike-in.


### Code and data availability

We used functional genomics data from the Genotype-Tissue Expression (GTEx) project to identify gene co-expression patterns associated with complex traits.
We then used clustering algorithms to group traits into clusters of related phenotypes.
Finally, we used the gene expression patterns associated with each cluster to identify therapeutic targets and drug repurposing opportunities. 

The code and data to reproduce the
