## Methods and materials {#sec:methods}

PhenoPLIER is a framework that combines different computational approaches to integrate gene-trait associations and drug-induced transcriptional responses with groups of functionally-related genes (referred to as gene modules or latent variables/LVs).
PrediXcan family of methods are used to compute gene-trait associations, whereas MultiPLIER models are applied on large gene expression compendia to infer latent variables.
PhenoPLIER provides the following three methods: 1) a regression model to compute an LV-trait association; 2) a consensus clustering approach applied to the latent space to learn shared and distinct transcriptomic properties between traits; and 3) an interpretable, LV-based drug repurposing framework.
The details of these methods are provided below.


### The PrediXcan family of methods for gene-based associations {#sec:methods:predixcan}

In both methods, the gene expression levels are predicted using a linear model based on a set of covariates, and the model parameters are estimated using a large reference panel of expression quantitative trait loci (eQTL) [@doi:10.1038/ng.3658].

We used Summary-PrediXcan (S-PrediXcan) [@doi:10.1038/s41467-018-03621-1] and Summary-MultiXcan (S-MultiXcan) [@doi:10.1371/journal.pgen.1007889] from the PrediXcan family of methods [@doi:10.1038/ng.3367] for our gene-based statistical approaches.
These approaches, referred to collectively as TWAS (transcription-wide association studies), require only GWAS summary statistics instead of individual-level genotype and phenotype data.
S-PrediXcan computes the univariate association between a trait and a gene's predicted expression in a single tissue, while S-MultiXcan computes the joint association between a gene's predicted expression in all tissues and a trait.
The gene expression levels are predicted using a linear model based on a set of covariates, and the model parameters are estimated using a large reference panel of expression quantitative trait loci (eQTL) [@doi:10.1038/ng.3658].

We briefly provide the details of the TWAS methods necessary to explain our regression framework later (see the referenced articles for more information).
For convenience, we refer to $\mathbf{y}$ as a vector of traits for $n$ individuals that is centered (no intercept is necessary).
We also denote $\mathbf{\tilde{t}}_l = \sum_{a \in \mathrm{model}_l} w_{a}^{l} X_{a}$ as the gene's predicted expression for all individuals in tissue $l$, where $X_a$ is the genotype of SNP $a$ and $w_{a}$ is its weight in the tissue prediction model $l$, and $\mathbf{t}_l$ is the standardized version of $\mathbf{\tilde{t}}_l$ with mean equal to zero and standard deviation equal to one.

We employed S-PrediXcan [@doi:10.1038/s41467-018-03621-1] to project genetic associations through gene expression patterns.
Using the univariate model 

$$
\mathbf{y} = \mathbf{t}_l \gamma_l + \bm{\epsilon}_l,
$$ {#eq:predixcan}

we calculated the $z$-score $\hat{z}_{l}=\hat{\gamma}_l / \mathrm{se}(\hat{\gamma}_l)$ for a gene's tissue model $l$.
Since S-PrediXcan provides tissue-specific direction of effects (e.g.
whether a higher or lower predicted expression of a gene confers more or less disease risk), we approximated the PrediXcan $z$-scores using only GWAS summary statistics with the expression

$$
\hat{z}_{l} \approx \sum_{a \in model_{l}} w_a^l \frac{\hat{\sigma}_a}{\hat{\sigma}_l} \frac{\hat{\beta}_a}{\mathrm{se}(\hat{\beta}_a)},
$$ {#eq:spredixcan}

where $\hat{\sigma}_a$ is the variance of SNP $a$, $\hat{\sigma}_l$ is the variance of the predicted expression of a gene in tissue $l$, and $\hat{\beta}_a$ is the estimated effect size of SNP $a$ from the GWAS.
All genotype variances and covariances were estimated using the Genotype-Tissue Expression project (GTEx v8) [@doi:10.1126/science.aaz1776] as the reference panel.
We used the resulting $z$-scores in our drug repurposing approach.

S-MultiXcan (as described in @doi:10.1371/journal.pgen.1007889) is a summary version of MultiXcan, which is more powerful than PrediXcan in detecting gene-trait associations, although it does not provide the direction of effects.
The main output of S-MultiXcan is the $p$-value (obtained with an F-test) of the multiple tissue model (Equation (@eq:multixcan)), which is derived from the marginal estimates from S-PrediXcan (Equation (@eq:spredixcan)).
Under the null hypothesis of no association, $\mathbf{\hat{g}}^{\top} \frac{\mathbf{T}^{\top}\mathbf{T}}{\sigma_{e}^{2}} \mathbf{\hat{g}} \sim \chi_{p}^{2}$, and the significance of the association is estimated using $\mathbf{\hat{z}}^{\top} Cor(\mathbf{T})^{-1} \mathbf{\hat{z}} \sim \chi_k^2$ (Equation (@eq:smultixcan)).
To avoid collinearity issues, MultiXcan uses the principal components (PCs) of $\mathbf{T}$.
Additionally, S-MultiXcan uses the conservative approximation $\sigma_{e}^{2} \approx \sigma_{\epsilon}^{2}$, which is the variance of the error terms in the joint regression is approximately equal to the residual variance of the marginal regressions.
Moreover, $Cor(\mathbf{T})$ is estimated using a global genotype covariance matrix, whereas marginal $\hat{z}_l$ in Equation (@eq:spredixcan) are approximated using tissue-specific genotype covariances.
Although S-MultiXcan yields highly concordant estimates compared with MultiXcan, results are not perfectly correlated across genes [@doi:10.1371/journal.pgen.1007889].
We used S-MultiXcan results for our LV-based regression model and our cluster analyses of traits.


### TWAS resources {#sec:methods:twas}

We used two large TWAS resources from different cohorts for discovery and replication, all obtained from European ancestries.
PhenomeXcan [@doi:10.1126/sciadv.aba2083], our discovery cohort, provides results on 4,091 traits across different categories.
Details about the included GWAS, sample size and disease/trait categories can be found in Supplemenetary File 1.
PrediXcan family of methods (described before) was used in PhenomeXcan to compute gene-based associations, and fastENLOC [@doi:10.1126/sciadv.aba2083; @doi:10.1016/j.ajhg.2020.11.012] was used to compute a posterior probability of colocalization between GWAS loci and *cis*-eQTL.
The matrix of $z$-scores from S-PrediXcan (Equation (@eq:spredixcan)) across $q$ traits and $m$ genes in tissue $t$ was referred to as $\mathbf{M}^{t} \in \mathbb{R}^{q \times m}$.
This matrix was used in our LV-based drug repurposing framework since it provides direction of effects.
S-MultiXcan results (22,515 gene associations across 4,091 traits) were used in our LV-based regression framework and our cluster analyses of traits.
For the cluster analyses, $p$-values were converted to $z$-scores ($\mathbf{M}=\Phi^{-1}(1 - p/2)$) where $\Phi^{-1}$ is the probit function.
Higher $z$-scores correspond to stronger associations.

Our discovery cohort was eMERGE [@doi:10.1038/gim.2013.72], where the same TWAS methods were run on 309 phecodes [@doi:10.1101/2021.10.21.21265225] across different categories (more information about traits are available in [@doi:10.1101/2021.10.21.21265225]).
We used these results to replicate the associations found with our LV-based regression framework in PhenomeXcan.


### MultiPLIER and Pathway-level information extractor (PLIER) {#sec:methods:multiplier}

These LVs were then used to identify gene modules associated with disease phenotypes.

MultiPLIER was used to extract patterns of co-expressed genes from recount2, a large gene expression dataset.
The approach applied the Pathway-Level Information Extractor Method (PLIER) [@doi:10.1038/s41592-019-0456-1], which utilized unsupervised learning and prior knowledge (canonical pathways) to reduce technical noise.
MultiPLIER used matrix factorization to deconvolute gene expression data into 987 latent variables (LVs), each representing a gene module.
These LVs were then used to identify gene modules associated with disease phenotypes.

Using PLIER, a gene expression dataset $\mathbf{Y}^{m \times c}$ with $m$ genes and $c$ experimental conditions and a prior knowledge matrix $\mathbf{C} \in \{0,1\}^{m \times p}$ for $p$ MSigDB pathways [@doi:10.1016/j.cels.2015.12.004] is used to find $\mathbf{U}$, $\mathbf{Z}$, and $\mathbf{B}$ that minimize the following equation:

$$
||\mathbf{Y} - \mathbf{Z}\mathbf{B}||^{2}_{F} + \lambda_1 ||\mathbf{Z} - \mathbf{C}\mathbf{U}||^{2}_{F} + \lambda_2 ||\mathbf{B}||^{2}_{F} + \lambda_3 ||\mathbf{U}||_{L^1}
$$ {#eq:met:plier_func},

subject to $\mathbf{U}>0, \mathbf{Z}>0$.
$\mathbf{Z}^{m \times l}$ are the gene loadings with $l$ latent variables, $\mathbf{B}^{l \times c}$ is the latent space for $c$ conditions, $\mathbf{U}^{p \times l}$ specifies which of the $p$ prior-information pathways in $\mathbf{C}$ are represented for each LV, and $\lambda_i$ are different regularization parameters used in the training step.
This process yields a low-dimensional representation of the gene space, $\mathbf{Z}$, where each latent variable (LV) aligns as much as possible to prior knowledge and might represent either a known or novel gene module (i.e., a meaningful biological pattern) or noise.

For our drug repurposing and cluster analyses, we projected gene-trait associations (from TWAS) and gene-drug associations (from LINCS L1000) into a low-dimensional gene module space using the following equation: 

$$
\hat{\mathbf{M}} = (\mathbf{Z}^{\top} \mathbf{Z} + \lambda_{2} \mathbf{I})^{-1} \mathbf{Z}^{\top} \mathbf{M},
$$ {#eq:proj}

This equation allowed us to obtain a matrix, $\hat{\mathbf{M}}^{l \times q}$, in which traits were represented by gene modules instead of single genes.
The same approach was used to project drug-induced transcriptional profiles in LINCS L1000 to obtain a representation of drugs using gene modules.


### Regression model for LV-trait associations {#sec:methods:reg}

We adapted the gene-set analysis framework from MAGMA [@doi:10.1371/journal.pcbi.1004219] to TWAS, utilizing a competitive test to predict gene-trait associations.
This test evaluates whether genes with the largest loadings for a latent variable (LV) $\ell$ are more strongly associated with a trait than genes with relatively small or zero weights.
The model used is given by the equation:

$$
\mathbf{m}=\beta_{0} + \mathbf{s} \beta_{s} + \sum_{i} \mathbf{x}_{i} \beta_{i} + \bm{\epsilon},
$$ {#eq:reg:model}

where $\mathbf{m}$ is a vector of S-MultiXcan gene $p$-values for a trait (with a $-log_{10}$ transformation); $\mathbf{s}$ is a binary indicator vector with $s_{\ell}=1$ for the top 1% of genes with the largest loadings for LV $\ell$ (from $\mathbf{Z}_{\ell}$) and zero otherwise; $\mathbf{x}_{i}$ is a gene property used as a covariate; $\beta$ are effect sizes (with $\beta_{0}$ as the intercept); and $\bm{\epsilon} \sim \mathrm{MVN}(0, \sigma^{2} \mathbf{R})$ is a vector of error terms with a multivariate normal distribution (MVN) where $\mathbf{R}$ is the matrix of gene correlations.

We used gene size and gene density to control for the effect of the gene size and gene density on the trait association, respectively.

We tested the null hypothesis $\beta_{s} = 0$ against the one-sided hypothesis $\beta_{s} > 0$, where $\beta_{s}$ reflects the difference in trait associations between genes that are part of the latent variable $\ell$ and genes outside of it.
To account for the effect of gene size and gene density on trait associations, we used the MAGMA framework and included two gene properties as covariates: gene size (defined as the number of principal components retained in S-MultiXcan) and gene density (defined as the ratio of the number of principal components to the number of tissues available).

We used the same correlation matrix $\mathbf{R}$ in all the PrediXcan-based methods described here.

Since the error terms $\bm{\epsilon}$ could be correlated, we could not assume they had independent normal distributions as in a standard linear regression model.
To account for these correlations, we used a generalized least squares approach and approximated the gene-gene correlation matrix $\mathbf{R}$ by computing the correlations between the model sum of squares (SSM) for each pair of genes under the null hypothesis of no association.
The correlations were derived from the individual-level MultiXcan model (Equation (@eq:multixcan)), where the predicted expression matrix $\mathbf{T}_{i} \in \mathbb{R}^{n \times p_i}$ of a gene $i$ across $p_i$ tissues was projected into its top $k_i$ PCs, resulting in matrix $\mathbf{P}_{i} \in \mathbb{R}^{n \times k_i}$.
The covariances between the SSM of genes $i$ and $j$ were given by $2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})$, and the standard deviations of each SSM were given by $\sqrt{2 \times k_{i}} \times (n - 1)$.
The correlation between the SSMs for genes $i$ and $j$ was expressed as follows (Equation (@eq:reg:r)): 

$$
\mathbf{R}_{ij} = \frac{2 \times \mathrm{Tr}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}} \times (n - 1)^2},
$$

where columns $\mathbf{P}$ were standardized, $\mathrm{Tr}$ was the trace of a matrix, and the cross-correlation matrix between PCs $Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \in \mathbb{R}^{k_i \times k_j}$ was given by Equation (@eq:reg:cor_pp).
To estimate the correlation of predicted expression levels for genes $i$ in tissue $k$ and gene $j$ in tissue $l$, $(\mathbf{t}_k^i, \mathbf{t}_l^j)$ ($\mathbf{t}_k^i$ is the $k$th column of $\mathbf{T}_{i}$), we used Equation (@eq:reg:corr_genes) and the variance of the predicted expression values of gene $i$ in tissue $k$ was estimated as Equation (@eq:reg:var_gene).
S-MultiXcan kept only the top eigenvectors using a condition number threshold of $\frac{\max(\lambda_i)}{\lambda_i} < 30$.
We used the same correlation matrix $\mathbf{R}$ in all the PrediXcan-based methods described here.

We used the MultiXcan regression model (Equation (@eq:multixcan)) to approximate gene correlations in S-MultiXcan.
To account for the fact that S-MultiXcan approximates the joint regression parameters in MultiXcan using the marginal regression estimates from S-PrediXcan (Equation (@eq:spredixcan)) with some simplifying assumptions and different genotype covariance matrices, we used a submatrix $\mathbf{R}_{\ell}$ corresponding to genes that are part of LV $\ell$ only (top 1% of genes) instead of the entire matrix $\mathbf{R}$.
This simplification is conservative, as correlations are accounted for only in the top genes.
Our simulations ([Supplementary Note 1](#sm:reg:null_sim)) show that the model is approximately well-calibrated, and can correctly identify LVs with adjacent and highly correlated genes at the top (e.g., Figure @fig:reg:nulls:qqplot:lv234).
Furthermore, the model has been able to detect LVs associated with relevant traits (Figure @fig:lv246 and Table @tbl:sup:phenomexcan_assocs:lv246) that are replicated in a different cohort (Table @tbl:sup:emerge_assocs:lv246).

For eMERGE, we used a single correlation matrix for each set of traits, since the SNPs used in the GWAS were different for each set.

We computed correlation matrices for PhenomeXcan and eMERGE by considering only tissue models present in S-PrediXcan results and SNPs present in GWAS used as input for the TWAS approaches (Equation (@eq:reg:corr_genes)).
This was necessary to obtain more accurate correlations estimates [@doi:10.1371/journal.pgen.1007889].
For PhenomeXcan, we used a single correlation matrix for the 4,049 GWAS obtained from the UK Biobank using the same pipeline and including the same set of SNPs.
For the remaining GWAS, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.
For eMERGE, we used a single correlation matrix for each set of traits, since the SNPs used in the GWAS were different for each set.

We ran our regression model for all 987 LVs across the 4,091 traits in PhenomeXcan.
For replication, we ran the model in the 309 phecodes in eMERGE.
We adjusted the $p$-values using the Benjamini-Hochberg procedure.


### LV-based drug repurposing approach {#sec:methods:drug}

We derived a Latent Variable (LV)-based method based on a drug repositioning framework previously used for psychiatry traits [@doi:10.1038/nn.4618] to predict drug-disease associations.
This method was compared to a single-gene approach.
For the single-gene method, we computed a drug-disease score by multiplying each S-PrediXcan set of signed $z$-scores in tissue $t$, $\mathbf{M}^t$, with another set of signed $z$-scores from transcriptional responses profiled in LINCS L1000 [@doi:10.1016/j.cell.2017.10.049], $\mathbf{L}^{c \times m}$ (for $c$ compounds).
This product yielded $\mathbf{D}^{t,k}=-1 \cdot \mathbf{M}^{t,k} \mathbf{L}^\top$, where $k$ refers to the number of most significant gene associations in $\mathbf{M}^t$ for each trait.
We considered $k$ to be either all genes or the top 50, 100, 250, and 500, and then averaged the score ranks across all $k$ to obtain $\mathbf{D}^t$.
Finally, for each drug-disease pair, the maximum prediction score across all tissues was taken: $\mathbf{D}_{ij} = \max \{ \mathbf{D}_{ij}^t \mid \forall t \}$.


The same procedure was used for the LV-based approach, where we projected $\mathbf{M}^{t}$ and $\mathbf{L}$ into the gene module latent space using Equation (@eq:proj), leading to $\hat{\mathbf{M}}^t$ and $\hat{\mathbf{L}}^{l \times c}$, respectively.
Finally, $\mathbf{D}^{t,k}=-1 \cdot \hat{\mathbf{L}}^{\top} \hat{\mathbf{M}}^{t,k}$, where in this case $k$ could be all LVs or the top 5, 10, 25 and 50 (since we have an order of magnitude less LVs than genes).


Since the gold standard of drug-disease medical indications is described with Disease Ontology IDs (DOID) [@doi:10.1093/nar/gky1032], we mapped PhenomeXcan traits to the Experimental Factor Ontology [@doi:10.1093/bioinformatics/btq099] using [@url:https://github.com/EBISPOT/EFO-UKB-mappings], and then to DOID.


### Consensus clustering of traits {#sec:methods:clustering}

We performed two preprocessing steps on the S-MultiXcan results before the cluster analysis.
First, we combined results in $\mathbf{M}$ (with $p$-values converted to $z$-scores, as described before) for traits that mapped to the same Experimental Factor Ontology (EFO) [@doi:10.1093/bioinformatics/btq099] term using the Stouffer's method: $\sum w_i M_{ij} / \sqrt{\sum w_i^2}$, where $w_i$ is a weight based on the GWAS sample size for trait $i$, and $M_{ij}$ is the $z$-score for gene $j$.
Second, we divided all $z$-scores for each trait $i$ by their sum to reduce the effect of highly polygenic traits: $M_{ij} / \sum M_{ij}$.
Finally, we projected this data matrix using Equation (@eq:proj), obtaining $\hat{\mathbf{M}}$ with $n=3,752$ traits and $l=987$ Latent Variables (LVs) as the input of our clustering pipeline.


A partitioning of $\hat{\mathbf{M}}$ with $n$ traits into $k$ clusters is represented as a label vector $\pi \in \mathbb{N}^n$.
Consensus clustering approaches consist of two steps: 1) the generation of an ensemble $\Pi$ with $r$ partitions of the dataset: $\Pi=\{\pi_1, \pi_2, \ldots, \pi_r\}$, and 2) the combination of the ensemble into a consolidated solution.
This solution is defined as:

$$
\pi^* = \mathrm{arg}\,\underset{\hat{\pi}}{\max} Q(\{ \lvert \mathcal{L}^i \lvert \phi(\hat{\pi}_{\mathcal{L}^i}, \pi_{i \mathcal{L}^i}) \mid i \in \{1,\ldots,r\} \}),
$$ {#eq:consensus:obj_func}

where $\mathcal{L}^i$ is a set of data indices with known cluster labels for partition $i$, $\phi\colon \mathbb{N}^n \times \mathbb{N}^n \to \mathbb{R}$ is a function that measures the similarity between two partitions, and $Q$ is a measure of central tendency, such as the mean or median.
We used the adjusted Rand index (ARI) [@doi:10.1007/BF01908075] for $\phi$ and the median for $Q$.
To obtain $\pi^*$, we define a consensus function $\Gamma\colon \mathbb{N}^{n \times r} \to \mathbb{N}^n$ with $\Pi$ as the input.
We employed consensus functions based on the evidence accumulation clustering (EAC) paradigm [@doi:10.1109/TPAMI.2005.113], which first transforms $\Pi$ into a distance matrix $\mathbf{D}_{ij} = d_{ij} / r$, where $d_{ij}$ is the number of times traits $i$ and $j$ were grouped in different clusters across all $r$ partitions in $\Pi$.
Then, $\Gamma$ is any similarity-based clustering algorithm, which is applied on $\mathbf{D}$ to derive the final partition $\pi^*$.


We used different algorithms to create a highly diverse set of partitions (see Figure @fig:clustering:design) since diversity is an important property for ensembles [@doi:10.1016/j.ins.2016.04.027; @doi:10.1109/TPAMI.2011.84; @doi:10.1016/j.patcog.2014.04.005].
We used three data representations: the raw dataset, its projection into the top 50 principal components, and the embedding learned by UMAP [@arxiv:1802.03426] using 50 components.
For each of these, we applied five clustering algorithms: $k$-means [@Arthur2007], spectral clustering [@Ng2001], a Gaussian mixture model (GMM), hierarchical clustering, and DBSCAN [@Ester1996].
We specified a range of $k$ between 2 and $\sqrt{n} \approx 60$ for $k$-means, spectral clustering and GMM, and generated five partitions using random seeds for each $k$.
For hierarchical clustering, we generated four partitions using common linkage criteria: ward, complete, average and single.
For DBSCAN, we combined different ranges for parameters $\epsilon$ (the maximum distance between two data points to be considered part of the same neighborhood) and *minPts* (the minimum number of data points in a neighborhood for a data point to be considered a core point), based on the procedure in [@doi:10.1088/1755-1315/31/1/012012].
Specifically, we used *minPts* values from 2 to 125 and determined a plausible range of $\epsilon$ values by observing the distribution of the mean distance of the *minPts*-nearest neighbors across all data points.
We resampled partitions generated by DBSCAN to ensure an equal representation of this algorithm in the ensemble.
This procedure generated a final ensemble of 4,428 partitions of 3,752 traits.


Finally, we used spectral clustering on $\mathbf{D}$ to derive the final consensus partitions.
We first transformed $\mathbf{D}$ into a similarity matrix by applying an RBF kernel $\mathrm{exp}(-\gamma \mathbf{D}^2)$, using four different values of $\gamma$ that were empirically determined to work best.
For each $k$ between 2 and 60, we derived four consensus partitions and selected the one that maximized Equation (@eq:consensus:obj_func).
To further filter this set of 59 solutions, we kept only those with an ensemble agreement higher than the 75th percentile (Supplementary Figure @fig:sup:clustering:agreement), leaving a total of 15 final consensus partitions shown in Figure @fig:clustering:tree.

Our clustering pipeline involved several linear and nonlinear transformations, such as PCA, UMAP, and the ensemble transformation using the EAC paradigm (distance matrix $\mathbf{D}$).
Although consensus clustering has advantages for biological data [@pmid:27303057], this set of data transformations complicates the interpretation of results.
To address this, we used a supervised learning approach to identify the most important gene modules/LVs for each cluster of traits (Figure {@fig:clustering:design}b).
This supervised model was not used for prediction but to learn which features (LVs) were most discriminative for each cluster.
We used the highest resolution partition ($k$=29) to train a decision tree model, with each of the clusters as labels and the projected data $\hat{\mathbf{M}}$ as the training samples.
For each $k$, we created a set of binary labels with the current cluster's traits as the positive class and the rest of the traits as the negative class.
We then selected the LV in the root node of the trained model if its threshold was positive and larger than one standard deviation.
We removed this LV from $\hat{\mathbf{M}}$ and trained the model again.
We repeated this procedure 20 times to identify the top 20 LVs that best discriminate a cluster's traits from the rest.

In [Supplementary Note 2](#sm:clustering:null_sim), we performed several analyses under a null hypothesis of no structure in the data to verify that the clustering results detected by this pipeline were real.


### CRISPR-Cas9 screening {#sec:methods:crispr}

HepG2 cells were obtained from ATCC (ATCC® HB-8065™) and grown in Eagle's Minimum Essential Medium with L-Glutamine (EMEM, Cat.
112-018-101, Quality Biology), supplemented with 10% Fetal Bovine Serum (FBS, Gibco, Cat.16000-044) and 1% Pen/Strep (Gibco, Cat.15140-122).
The cells were incubated at 37°C in a humidity-controlled environment with 5% CO2, and the density of the cells was kept below 80% confluency.

The number of successful transduced cells were determined by flow cytometry (FACS) using the fluorescent protein mCherry.

The 3rd generation Broad GPP Human Brunello CRISPR knockout Pooled library was used for HepG2 cell transduction.
This library consists of 76,441 sgRNAs that target 19,114 genes in the human genome, with an average of 4 sgRNAs per gene.
The sgRNA cassette was inserted into the lentiCRIS-PRv2 backbone between the U6 promoter and gRNA scaffold.
Lentiviral vectors encoding Cas9 were used to deliver the sgRNA cassette containing plasmids into cells during cell replication.
Unsuccessful transduced cells were excluded through puromycin selection, and the number of successful transduced cells were determined by flow cytometry (FACS) using the fluorescent protein mCherry.

Lentiviral titer determination was conducted using no-spin transduction.
Cells were seeded in a Collagen-I coated 6-well plate with 8ug/ml of polybrene and different volumes of virus (0, 50, 100, 200, 250, and 400ul) assigned to each well.
The cells were then incubated with EMEM complete media before being washed twice with DPBS.
After 24 hours, the cells were trypsinized, diluted (1:10), and seeded in pairs of wells of 6-well plates.
At 60 hours post-transduction, the cell media in each well was replaced with fresh EMEM, and 2ug/ml of puromycin was added to one well out of the pair.
After 2-5 days, the cells in both wells with/without puromycin were collected and counted for viability.
The percentage of infection (PI%) was calculated by comparing the cell numbers with/without puromycin selection within each pair.
Using Poisson's distribution theory, when the PI% is between 30-50%, it corresponds to an MOI of ~0.35-0.70.
At an MOI of 0.3, 95% of infected cells are predicted to have only one copy of the virus.
Therefore, a virus volume of 120ul yielding 30-40% transduction efficiency was chosen for further large-scale viral transduction.

To achieve a coverage of at least 500 cells per sgRNA, with 95% of infected cells receiving one viral particle per cell, 2.5 million cells were seeded in each of 14 6-well plates with 8 μg/ml of polybrene.
120 μl of virus was then added to each experimental well.
18 hours post-transduction, the virus/PB mix medium was removed, and cells from each well were collected, counted, and pooled into T175 flasks.
At 60 hours post-transduction, 2 μg/ml of puromycin was added to each flask, and the mediums were changed every two days with fresh EMEM, topped with 2 μg/ml of puromycin.
Seven days after puromycin selection, the cells were collected, pooled, counted, and replated.

Cells were stained with LipidSpotTM 488 (Biotium, Cat.
70065-T) to assess gene expression patterns.
For this, the cells (approximately 200M) were kept in 100mm dishes and 4ml of LipidSpot 488 (diluted 1:100 with DPBS) was added to each dish.
The dishes were incubated at 37°C for 30 minutes before fluorescent microscope EVOS was used to capture cell images for GFP signal detection (Figure @fig:sup:crispr:fig1).
Additionally, 20-30M cells were collected as Unsorted Control, spun down at 500 x g for 5 minutes at 4°C, and the dry pellet was kept at -80°C for further genomic DNA isolation.

Cells were collected into 50 mL tubes and spun at 500xg for 5 minutes at 4°C.
After a DPBS wash, cell pellets were resuspended in FACS Sorting Buffer (1x DPBS without Ca2+/Mg2+, 2.5 mM EDTA, 25 mM HEPES, 1% BSA; the solution was filter sterilized and kept at 4°C) and gently pipetted to form single cells.
The cell solution was then filtered through a cell strainer (Falcon, Cat.
352235) and kept on ice, protected from light.
The cells were sorted on a FACSJazz, using a 100 μm nozzle, collecting ~20% of each GFP-High and GFP-Low (Figure @fig:sup:crispr:fig2) into 15 mL tubes.
After sorting, cells were immediately spun down and the pellets were kept at -80°C for further genomic DNA isolation.

Genomic DNA was isolated from three conditions (Un-Sorted Control, lentiV2 GFP-High, and lentiV2 GFP-Low) using the QIAamp DNA Blood Mini Kit (Qiagen, Cat.51104).
The quality and quantity of the gDNA were then assessed with UV Spectroscopy (Nanodrop).
For each condition, 80-160ug of gDNA was isolated.
PCR was used to verify the presence of the sgRNA cassette and lentiviral specific transgene in the isolated gDNA (Figure @fig:sup:crispr:fig3).

Illumina libraries were generated and sequenced for this study.
Primers (P5/P7) were adapted from the Broad Institute protocol (Figure @fig:sup:crispr:table1) and contained a staggered sequence (0-8nt) in P5 and 8bp uniquely barcoded sequence in P7.
The primers were synthesized by Integrated DNA Technologies (IDT) and PAGE purified.
32 PCR reactions (100ul each) were set up for each condition, each containing roughly 5ug of gDNA, 5ul of each 10uM P5 and P7, and ExTaq DNA Polymerase (TaKaRa, Cat.
RR001A).
The PCR Thermal Cycler was set with an initial temperature of 95oC for 1min; followed by 24 cycles of denaturation at 94oC for 30 seconds, annealing at 52.5oC for 30 seconds, and extension at 72oC for 30 seconds.
A final elongation at 72oC for 10 minutes yielded a 285bp-293bp PCR product (Figure @fig:sup:crispr:fig4 A).
The PCR products were pooled and purified using SPRIselect beads (Beckman Coulter, Cat.
B23318).
The purified libraries were quantitated on Qubit and the quality of the library was analyzed on Bio-analyzer using High Sensitivity DNA Chip (Figure @fig:sup:crispr:fig4 B).
Finally, the Illumina library samples were sequenced on Nova-seq 6000.
Samples were pooled and loaded on an SP flow cell, along with a 20% PhiX control v3 library spike-in.


### Code and data availability

The code and data to reproduce all the analyses in this work are available in [https://github.com/greenelab/phenoplier](https://github.com/greenelab/phenoplier).
